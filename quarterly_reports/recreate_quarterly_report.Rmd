---
title: "Create Quarterly Report"
data: "2021-05-10"
---

# ‚≠êÔ∏èOverview

# üìåDelete text

Trying to recreate the last quarterly report (/Users/bradcannell/Dropbox/01 Research/link2care/L2C_Quarterly_Data_Code_Files/Link2Care Quarterly Q3_2020_final.docx).

Soon, I will have to start making these myself.

**Start by just getting the report done**, then move to improving efficiency of the code. Don't get bogged down in optimizing right now.
   * 2020-12-15. I ran out of time and basically just created the table manually.
   * In the future, improve the report and make it more automated (officer).
   * Below, there are some notes for improvement. Search for "NOTES".
   

# üì¶Load packages

```{r message=FALSE}
library(dplyr)
library(readxl)
library(freqtables)
library(meantables)
library(stringr)
library(tidyr)
library(forcats)
library(purrr)
library(ggplot2)
library(lubridate)
library(officer)
library(flextable)
```


# üåéConnect to UTH server 

```{bash eval=FALSE}
# Make sure you are connected to the VPN
# Don't drill all the way down to live documents because not all of the data is in live documents.
open 'smb://islgpcifs.uthouston.edu/sph_research/Link2Care/'
```


# üì•Import data 

# üìå Move import
**NOTES:** Once everything is working, I should probably move all the data import to the top of the file.

This data was created in...

```{r}

```

```{r}
# dim()
```


# üößData management

## üßÆRecode/calculate variables


# üìàAnalysis

# Section 1 - Study participants

## Import data

Demographics data for Tables 1 and 2. 

**NOTES:** You might eventually want to switch this over to pull directly from the master log instead of the created demographics spreadsheets.

```{r}
screened_in <- read_excel(
  "/Volumes/link2Care/Live Documents/L2C_Demographics.xlsx", 
  sheet = "Screened In",
  col_names = c(
    "id", "date_consented", "status", "group", "gender", "hispanic", "race", "age", 
    "zip"
  ),
  col_types = c(
    "numeric", "date", "text", "text", "text", "text", "text", "numeric", 
    "numeric", "skip", "skip"
  ),
  skip = 1
)
```

```{r}
screened_out <- read_excel(
  "/Volumes/link2Care/Live Documents/L2C_Demographics.xlsx", 
  sheet = "Screened Out",
  col_names = c(
    "id", "date_consented", "status", "gender", "hispanic", "race", "age", 
    "zip"
  ),
  col_types = c(
    "numeric", "date", "text", "text", "text", "text", "numeric", "numeric", 
    "skip", "skip", "skip"
  ),
  skip = 1
)
```

Combine screened in and screened out for easier data manipulation below.

```{r}
# Variable to identify which data frame each record came from
screened_in$screened_in <- 1L
screened_out$screened_in <- 0L
# Bind rows
demographics <- bind_rows(screened_in, screened_out)
# Factorize screened_in variable
demographics$screened_in_f <- factor(
  demographics$screened_in, labels = c("Screened-Out", "Screened-In")
)
# Drop individual data frames
rm(screened_in, screened_out)
```

## Data management

Recode variables and create factors

```{r}
demographics <- demographics %>% 
  mutate(
    gender_f = factor(gender, c("Male", "Female", "Other")),
    race_3cat = case_when(
      is.na(race) ~ NA_character_,
      race == "Black or African American" ~ "Black or African American",
      race == "White" ~ "White",
      TRUE ~ "Other"
    ),
    race_3cat_f = factor(
      race_3cat,
      c("Black or African American", "White", "Other")
    ),
    hispanic_f = factor(
      hispanic,
      c("Non-Hispanic", "Hispanic or Latino"),
      c("Non-Hispanic", "Hispanic")
    )
  )
```


## Analysis

### Helper functions

NOTES: I'm creating a custom function below for analyzing age (and possibly other continuous variables below). I'm doing so for two reasons: 1. mean_tables doesn't calculate standard deviation, and 2. The column names from mean_table and freq_table don't align well. I've added both to these as issues in the meantables package (#11 and #12).

```{r}
# Helper function for analyzing continuous variables (age) for Table 1 and 
# Table 2
# -----------------------------------------------------------------------------
get_mean_sd <- function(.data, .x, digits) {
  .data %>% 
    filter(!is.na({{.x}})) %>% 
    summarize(
      var  = !!quo_name(enquo(.x)),
      # Do this for easier row binding below
      cat  = NA_character_,
      mean = mean({{.x}}) %>% round(digits),
      sd   = sd({{.x}}) %>% round(digits),
      formatted_stats = paste0(mean, " (", sd, ")")
    ) %>% 
    select(var, cat, formatted_stats)
}

# For testing
# demographics %>% 
#   get_mean_sd(age, "Age in years, mean (sd)", 1)
```

### Table 1. Demographic characteristics of all people screened-in.

```{r}
cont_stats <- demographics %>%
  filter(screened_in == 1) %>% 
  get_mean_sd(age, 1) %>% 
  # Add blank row below
  add_row(var = "", cat = "", formatted_stats = "")
```

NOTES: Right now, I have to use purrr::map_df to use freq_table over multiple categorical variables. In the future, I'd to either create a wrapper function for this or make a really good vignette for using this method. Created issues in freqtables (#23, #36).

NOTES: Create a function to add an empty row. For now, I'm just adding this to the data frame manually. I've asked if there is a way to do this in flextable on [StackOverflow](https://stackoverflow.com/questions/64932726/add-a-blank-row-in-flextable). I've also created an issue in freqtables to create a wrapper function to do this (#35).

```{r}
# Loop over all categorical vars
cat_stats <- map_df(
  quos(gender_f, race_3cat_f, hispanic_f), 
  function(x) {
    demographics %>%
      filter(screened_in == 1) %>% 
      freq_table({{x}}) %>%
      freq_format(recipe = "n (percent)", digits = 1) %>%
      select(var, cat, formatted_stats) %>%
      # Add a row with the var name only
      add_row(var = quo_name(x), .before = 1) %>% 
      # Add blank row below
      add_row(var = "", cat = "", formatted_stats = "")
  }
) %>% 
  # Drop the final empty row
  slice(-n())
```

```{r}
table_1 <- cont_stats %>% 
  bind_rows(cat_stats) %>% 
  rename(screened_in = formatted_stats)
```

# üìåNOTE

2020-12-15:

Didn't have time to come back and make the report pretty/automated. But, here and below, I will output flextables to Word documents for easier cut and paste into the report that I'm manually creating.

Also, in the original report Table 1 and Table 2 were separate tables. They are going to be one table in the report I'm creating. Need to make this automated in the future.

```{r}
# Good - save for when I make pretty/automated
# table_1 <- table_1 %>%
#   mutate(
#     # Slide categories over
#     var = if_else(is.na(cat), var, cat)
#   ) %>% 
#   select(-cat)
```

```{r}
# Good - save for when I make pretty/automated
# # Use for bolding below
# header_fmt <- fp_text(font.size = 11, bold = TRUE, font.family = "Times New Roman")
# 
# table_1_ft <- flextable(table_1) %>%
#   # Change column widths
#   width(width = 3.5) %>% 
#   # Remove vertical cell padding
#   padding(padding = 0, part = "all") %>% 
#   # Remove current header (var and formatted_stats)
#   merge_at(i = 1, part = "header") %>% 
#   # Overwrite current header with title
#   compose(
#     part = "header",
#     value = as_paragraph(
#       as_chunk("Table 1. ", props = header_fmt),
#       "Demographic characteristics of all people screened-in (n = ",
#       nrow(filter(demographics, screened_in == 1)), ")."
#     ),
#   ) %>% 
#   # Remove top border from title
#   hline_top(part = "header", border = fp_border(width = 0)) %>%
#   hline_bottom(part = "header", border = fp_border(width = 1)) %>%
#   # Bold variable names
#   compose(
#     i = 1, j = 1,
#     value = as_paragraph(
#       as_chunk("Age in years", props = header_fmt), ", mean (sd)"
#     )
#   ) %>% 
#   compose(
#     i = 3, j = 1,
#     value = as_paragraph(
#       as_chunk("Gender", props = header_fmt), ", n(%)"
#     )
#   ) %>% 
#   compose(
#     i = 8, j = 1,
#     value = as_paragraph(
#       as_chunk("Race", props = header_fmt), ", n(%)"
#     )
#   ) %>% 
#   compose(
#     i = 13, j = 1,
#     value = as_paragraph(
#       as_chunk("Ethnicity", props = header_fmt), ", n(%)"
#     )
#   ) %>% 
#   # Indent categories
#   padding(i = c(4:6, 9:11, 14:15), j = 1, padding.left = 10) %>% 
#   # Left align title
#   align(align = "left", part = "header") %>% 
#   # Left align first column
#   align(j = 1, align = "left", part = "body") %>% 
#   # Center align second column
#   align(j = 2, align = "center", part = "body") %>% 
#   # Change font to TNR 11
#   font(fontname = "Times New Roman", part = "all") %>% 
#   # Resize bottom border
#   hline_bottom(border = fp_border(width = 1))
```

* Format title border
* Add n = to title

# üìåNOTE

**NOTES:** A lot of the formatting (e.g., bold, indent) I did manually above is stuff that I will want to do all the time. It might be nice to create a wrapper function or wrapper functions.

2020-12-02:

Getting behind on the L2C report. For now, I just need to make sure I can do the calculations necessary to manually fill in the tables in the quarterly report (due the 16th). Afterward, if there is time, I will come back and make it pretty/automated.

2020-12-15:

Didn't have time to come back and make the report pretty/automated. But, here and below, I will output flextables to Word documents for easier cut and paste into the report that I'm manually creating.

Also, in the original report Table 1 and Table 2 were separate tables. They are going to be one table in the report I'm creating. Need to make this automated in the future.

### Table 1. Demographic characteristics of all people screened-out.

```{r}
cont_stats <- demographics %>%
  filter(screened_in == 0) %>% 
  get_mean_sd(age, 1) %>% 
  # Add blank row below
  add_row(var = "", cat = "", formatted_stats = "")
```

```{r}
# Loop over all categorical vars
cat_stats <- map_df(
  quos(gender_f, race_3cat_f, hispanic_f), 
  function(x) {
    demographics %>%
      filter(screened_in == 0) %>% 
      freq_table({{x}}) %>%
      freq_format(recipe = "n (percent)", digits = 1) %>%
      select(var, cat, formatted_stats) %>%
      # Add a row with the var name only
      add_row(var = quo_name(x), .before = 1) %>% 
      # Add blank row below
      add_row(var = "", cat = "", formatted_stats = "")
  }
) %>% 
  # Drop the final empty row
  slice(-n())
```

Add screened out statistics to Table 1

```{r}
table_1 <- table_1 %>%
  bind_cols(
    cont_stats %>% 
      bind_rows(cat_stats) %>% 
      rename(screened_out = formatted_stats) %>% 
      select(screened_out)
  )
```

Create flextable object

```{r}
table_1_ft <- flextable(table_1)
```

Calculate group sizes for Table 1 (automate in the future).

```{r}
demographics %>% 
  summarise(
    total = n(),
    n_screened_in = sum(screened_in == 1),
    n_screened_out = sum(screened_in == 0)
  )
```

### Output Word document for easy copy paste

# üìå NOTE

**NOTES:** Delete all these separate Word documents with tables after you make the big automated report.

```{r}
read_docx() %>%
  body_add_flextable(table_1_ft) %>% 
  print("table_1_2021_05_10.docx")
```


# Section 2 - Screen out reasons

## Import data

For Table 3.

```{r}
screened_out_reasons <- read_excel(
  "/Volumes/link2Care/Live Documents/L2C_Master_Log.xlsm", 
  sheet = "Screened Out",
  col_names = c(
    "id", "reason_1", "reason_2", "reason_3"
  ),
  col_types = c(
    "numeric", rep("skip", 7), rep("text", 3), rep("skip", 3)
  ),
  na = c("", "N/A"),
  skip = 1
)
```

## Analysis

### Table 2. Distribution of reasons for screen-out.

# üìåNOTES

NOTES: Come back and wrap these in purrr::map_df.

NOTES: 2020-12-03, Jenn wants Table 3 to include all three reasons.

```{r}
unique(screened_out_reasons$reason_1)
```

```{r}
table_2_ft <- screened_out_reasons %>% 
  pivot_longer(
    reason_1:reason_3,
    names_to = "reason_number",
    names_prefix = "reason_",
    values_to = "reason"
  ) %>% 
  filter(!is.na(reason)) %>% 
  freq_table(reason) %>% 
  arrange(desc(n)) %>% 
  # Get n from n_total column
  add_row(cat = "Total", n = 57L, percent = 100.0) %>% 
  freq_format("n (percent)", digits = 1) %>%
  select(cat, formatted_stats) %>% 
  flextable()
```

### Output Word document for easy copy paste

# üìåNOTE

NOTES: Delete all these separate Word documents with tables after you make the big automated report.

```{r}
read_docx() %>%
  body_add_flextable(table_2_ft) %>% 
  print("table_2_2021_05_10.docx")
```


# Section 3 - Phone and ClinCard Breakdown

## Import data

For Table 4 and 5

```{r}
master_log_screened_in <- read_excel(
  "/Volumes/link2Care/Live Documents/L2C_Master_Log.xlsm",
  # For testing
  # "/Users/bradcannell/Desktop/L2C_Master_Log.xlsm",
  sheet = "Screened In",
  col_names = c(
    "id", "status", "date_baseline", "date_v2", "date_v3", "date_v4", "date_v5", 
    "group", "name_first", "name_middle_init", "name_last", "gender", "race", 
    "hispanic", "date_birth", "age", "clincard_id", "n_clincards", "phone_id", 
    "phone_number_l2c", "phone_n_distributed", "care_manager", "v1", "v2", "v3", 
    "v4", "v5", "v3_r_distributed", "v3_r_completed", "v4_r_distributed", 
    "v4_r_completed", "v5_r_distributed", "v5_r_completed"
  ),
  col_types = c(
    # Some of the dates must be imported as text because the have embedded 
    # notes (e.g., "no show")
    "numeric", "text", "date", rep("text", 11), "date", "numeric", "text", 
    "numeric", rep("text", 2), "numeric", "text", rep("numeric", 5), "skip", 
    rep("numeric", 6)
  ),
  na = c("", ".", "N/A"),
  skip = 1
)

# Print a message for when this file is being sourced
cat(
  paste0(Sys.Date(), ":"),
  "Master log imported with", nrow(master_log_screened_in), "rows and",
  ncol(master_log_screened_in),
  "columns.\n"
)

# 2021-05-10: Master log imported with 283 rows and 33 columns.
```

For Table 5 footnote about phone malfunctions

```{r}
phone_terminations <- read_excel(
  "/Volumes/link2Care/Live Documents/Link2Care Phone Terminations.xlsx", 
  sheet = "Terminations",
  col_names = c(
    "id", "group", "phone_1_reason", "phone_2_reason", "phone_3_reason",
    "phone_4_reason"
  ),
  col_types = c(
    "text", "text", rep("skip", 6), "text", rep("skip", 4), "text", 
    rep("skip", 4), "text", rep("skip", 4), "text"
  ),
  na = c(""),
  skip = 1
)
```

## Data management

* There were some merged rows in the Excel sheet that delineated different EMA structures. We will remove those rows from the data.
* Reshape wide to long
* Coerce reason to factor

```{r}
phone_terminations <- phone_terminations %>% 
  filter(!str_detect(id, "[a-zA-Z]")) %>% 
  pivot_longer(
    cols = phone_1_reason:phone_4_reason,
    names_to = "phone",
    names_pattern = "phone_(\\d)_reason",
    names_transform = list(phone = as.integer),
    values_to = "reason"
  ) %>% 
  mutate(
    reason_f = factor(reason) %>% fct_infreq()
  )
```

## Analysis

### Table 3. Payment card and phone loss.

Total number of ClinCards distributed

```{r}
sum(master_log_screened_in$n_clincards, na.rm = TRUE)
```

Total number of participants with ClinCard replacements

```{r}
sum(master_log_screened_in$n_clincards > 1, na.rm = TRUE)
```

Total number of phones distributed

```{r}
sum(master_log_screened_in$phone_n_distributed, na.rm = TRUE)
```

Total number of participants with phone replacements

```{r}
sum(master_log_screened_in$phone_n_distributed > 1, na.rm = TRUE)
```

Number of ClinCard replacements

```{r}
master_log_screened_in %>% 
  freq_table(n_clincards)
```

### Table 4. Phone distribution and replacement.

Total # of phones distributed overall

```{r}
sum(master_log_screened_in$phone_n_distributed, na.rm = TRUE)
```

Total # of participants in phone groups

# üìåNOTE

NOTES: 2020-12-03, from James, Phone groups are L2C and UCM+SP only.

```{r}
master_log_screened_in %>% 
  filter(group == "L2C" | group == "UCM+SP") %>% 
  nrow()
```

Total number of participants with phone replacements

```{r}
sum(master_log_screened_in$phone_n_distributed > 1, na.rm = TRUE)
```

Number of participants w/ phone replacement (UCM+SP)

```{r}
master_log_screened_in %>% 
  filter(group == "UCM+SP") %>% 
  summarise(sum(phone_n_distributed > 1, na.rm = TRUE))
```

Number of participants w/ phone replacement (L2C)

```{r}
master_log_screened_in %>% 
  filter(group == "L2C") %>% 
  summarise(sum(phone_n_distributed > 1, na.rm = TRUE))
```

Number of participants in UCM+SP w/ >1 phone replacement

```{r}
master_log_screened_in %>% 
  filter(group == "UCM+SP") %>% 
  summarise(sum(phone_n_distributed > 2, na.rm = TRUE))
```

Number of Participants in L2C w/ >1 phone replacement

```{r}
master_log_screened_in %>% 
  filter(group == "L2C") %>% 
  summarise(sum(phone_n_distributed > 2, na.rm = TRUE))
```

#### Footnote: Number of participants had phone replaced 1 time (2 phones per participant total).

```{r}
sum(master_log_screened_in$phone_n_distributed == 2, na.rm = TRUE)
```

#### Footnote: N by group and ids for 2 or more phone replacements due to malfunctions in the UCM+SP and L2C groups

The footnote under Table 5 that I'm trying to recreate says, "3 UCM+SP participants (2010, 2165, 2168) & 3 L2C participants (2099, 2124, 2189) replaced phone 2 times (3 phones per participant total) due to phone malfunctions."

# üìåNOTE

NOTES: I tried importing the issues and notes file to see if I could recreate this information. I could not find consistent use of a word like "malfunction" that I could search for to systematically update this number. Therefore, I'm going to leave a comment on the report asking James to update it manually.

NOTES: 2020-12-10, James and Addison changed how "Defective" is coded. It should appear more often now.

```{r}
master_log_screened_in %>% 
  filter(group == "UCM+SP" | group == "L2C") %>% 
  filter(phone_n_distributed > 2) %>% 
  arrange(desc(group))
```

```{r}
phone_terminations %>% 
  filter(reason_f == "Defective") %>% 
  arrange(group, id)
```


# Section 4 - Phone Terminations

Data "phone_terminations" imported above in section 3 - Phone and ClinCard Breakdown. It was needed for a footnote to Table 5.

## Data management

* Create a new variable that captures the ICF.

```{r}
phone_terminations <- phone_terminations %>% 
  mutate(
    icf = case_when(
      id <= 2073 ~ 1L,
      id <= 2153 ~ 2L,
      TRUE ~ 3L
    )
  )
```

## Analysis

### Table 5. Reasons for phone terminations by informed consent form iteration

Overall

```{r}
fig_1 <- phone_terminations %>% 
  filter(!is.na(reason_f)) %>% 
  freq_table(reason_f) %>% 
  mutate(
    cat_f = factor(cat),
    cat_f = fct_reorder(cat_f, n)
  ) %>% 
  ggplot(aes(cat_f, n)) +
    geom_bar(stat = "identity", fill = "#00519B") +
    geom_label(aes(label = n)) +
    coord_flip() +
    labs(
      # X in plot, but Y before flipping coordinates
      y = "Number of Phones"
    ) +
    theme_classic() +
    theme(
      axis.title.y = element_blank(),
      axis.text.y = element_text(color = "black"),
      axis.text.x = element_text(color = "black")
    ) 
```

Save figure for copy and paste into report

```{r}
ggsave("fig_1.jpeg", width = 7, height = 4)
```

By ICF

```{r}
table_5 <- phone_terminations %>% 
  filter(!is.na(reason_f)) %>% 
  freq_table(icf, reason_f) %>% 
  freq_format("n (percent_row)", digits = 1) %>% 
  arrange(desc(n)) %>% 
  select(row_cat, col_cat, formatted_stats) %>% 
  pivot_wider(
    names_from = "row_cat",
    values_from = c("formatted_stats")
  )
```

Create flextable object

```{r}
table_5_ft <- flextable(table_5)
```

Column totals for table 5.

```{r}
phone_terminations %>% 
  filter(!is.na(reason_f)) %>% 
  freq_table(icf, reason_f) %>% 
  distinct(row_cat, n_row)
```

### Output Word document for easy copy paste

# üìåNOTE

NOTES: Delete all these separate Word documents with tables after you make the big automated report.

```{r}
read_docx() %>%
  body_add_flextable(table_5_ft) %>% 
  print("table_5_2021_05_10.docx")
```


# Section 5 - Visit Compliance

## Import data

# üìåNOTE

```{r}
# Don't need. I already have the entire master long
# visit_compliance <- read_excel(
#   "/Volumes/link2Care/Live Documents/L2C_Master_Log.xlsm", 
#   sheet = "Screened In",
#   col_names = c(
#     "id", "group", "v_1", "v_2", "v_3", "v_4", "v_5"
#   ),
#   col_types = c(
#     "numeric", rep("skip", 6), "text", rep("skip", 14), rep("numeric", 5), 
#     rep("skip", 3)
#   ),
#   na = c("", "."),
#   skip = 1
# )
```

## Analysis

### Table 6. Number and percent of participants per L2C group.

```{r}
table_6_ft <- master_log_screened_in %>%
  freq_table(group) %>% 
  arrange(desc(n)) %>% 
  add_row(cat = "Total", n = 261L, percent = 100.0) %>% 
  freq_format("n (percent)", digits = 1) %>%
  select(cat, formatted_stats) %>% 
  flextable()
```

### Output Word document for easy copy paste

# üìåNOTE

NOTES: Delete all these separate Word documents with tables after you make the big automated report.

```{r}
read_docx() %>%
  body_add_flextable(table_6_ft) %>% 
  print("table_6_2021_05_10.docx")
```

### Table 7. Number and percent of participants who completed visits 1 through 5.

```{r}
table_7_overall <- master_log_screened_in %>% 
  pivot_longer(
    cols = v1:v5,
    names_to = "visit",
    names_prefix = "v",
    values_to = "complete"
  ) %>% 
  group_by(visit) %>% 
  summarise(
    n = sum(complete == 1, na.rm = TRUE),
    mean = mean(complete, na.rm = TRUE),
    percent = round(mean * 100, 1),
    .groups = "drop"
  ) %>% 
  freq_format("n (percent)", digits = 1) %>% 
  select(visit, formatted_stats)
```

Add visit compliance Excluding No Show V2 PTs

```{r}
table_7_w_v2 <- master_log_screened_in %>%
  filter(v2 == 1) %>% 
  pivot_longer(
    cols = v1:v5,
    names_to = "visit",
    names_prefix = "v",
    values_to = "complete"
  ) %>% 
  group_by(visit) %>% 
  summarise(
    n = sum(complete == 1, na.rm = TRUE),
    mean = mean(complete, na.rm = TRUE),
    percent = round(mean * 100, 1),
    .groups = "drop"
  ) %>% 
  freq_format("n (percent)", digits = 1) %>% 
  select(visit, formatted_stats)
```

Merged 7 overall and 7 with V2 together and make flextable.

```{r}
table_7_ft <- table_7_overall %>% 
  left_join(table_7_w_v2, by = "visit") %>% 
  flextable()
```

### Output Word document for easy copy paste

# üìåNOTE

NOTES: Delete all these separate Word documents with tables after you make the big automated report.

```{r}
read_docx() %>%
  body_add_flextable(table_7_ft) %>% 
  print("table_7_2021_05_10.docx")
```


# Section 6 - COVID-19

## Import data

# üìåNOTE

NOTES: This data was emailed to me by James. It should probably be added to the live documents folder. Waiting to hear back from James.

```{r}
remote <- read_excel(
  "/Volumes/Link2Care/Live Documents/L2C Remote Interview & Redcap Tracking Sheet.xlsx", 
  sheet = "Log",
  col_names = c(
    "id", "group", "visit", "surface_pro", "interviewer", "mode", "date_visit", 
    "date_data_transfer", "notes"
  ),
  col_types = c(
    "numeric", "text", "numeric", rep("text", 3), rep("date", 2), "text"
  ),
  skip = 3
)
```

## Data management

```{r}
remote <- remote %>% 
  mutate(
    group_f = factor(group, c("UCM", "UCM + SP", "L2C"))
  )
```

## Analysis

### Table 7. COVID-19 Phone Interviews Since Protocol Change on 3/17/2020. 

Total

```{r}
remote %>% 
  summarise(
    n = n(),
    n_unique = length(unique(id))
  )
```

By group

```{r}
count(remote, group_f)
```

By visit

```{r}
count(remote, visit)
```


# Section 7 - EMA and Study Completion Rates

## Import data

# üìåNOTE

NOTES: Eventually, I will pull this data directly from Insight. Need to learn how to use Insight first.

Download the data from Kiteworks needed to recreate the stats for Table 9 about participants who received the initial payment approach. These stats shouldn't change over time. I just want to check them to be thorough.

* Kiteworks -> Link2Care -> EMA Comparison -> ema_data comparison.xlsx

```{r}
ema_initial_pay_approach <- read_excel(
  "/Volumes/Link2Care/Live Documents/ema_data comparison.xlsx",
  sheet = "Old EMA",
  range = "A2:N48",
  col_names = c(
    "id", "group", paste("emas", 1:12, sep = "_")
  ),
  col_types = c(
    "numeric", "text", rep("numeric", 12)
  )
)
```

```{r}
ema <- read_excel(
  "/Volumes/link2Care/Live Documents/15_Day_EMA.xlsx",
  sheet = "15_Day_EMA_Log",
  col_names = c(
    "id", "group", paste("emas", 1:12, sep = "_")
  ),
  col_types = c(
    "numeric", "skip", "text", rep(c(rep("skip", 5), "numeric"), 12), rep("skip", 7)
  ),
  skip = 1
)
```

## Data management

Keep UCM+SP and L2C rows only for EMA analysis.

Also, only keep participants who have gone through all 12 cycles (id < 2233). Right now, I'm just looking that up on the spreadsheet. Later, I need to come up with a better way. Maybe be scheduled completion date.

```{r}
# Check for misspellings
unique(ema$group)
```


```{r}
ema <- ema %>% 
  filter(group %in% c("UCM+SP", "L2C")) %>% 
  filter(id < 2233)
```

Setting NA to zero in 15 day EMA log

# üìåNOTE

NOTES: This should be happening directly in the Excel file. Let James know about it later.

```{r}
ema <- ema %>% 
  mutate(
    across(
      emas_1:emas_12,
      ~if_else(is.na(.x), 0, .x)
    )
  )
```

Add a column for total EMAs completed

```{r}
ema_initial_pay_approach <- ema_initial_pay_approach %>% 
  rowwise() %>% 
  mutate(emas_total = sum(c_across(emas_1:emas_12))) %>% 
  ungroup()
```

```{r}
ema <- ema %>% 
  rowwise() %>% 
  mutate(emas_total = sum(c_across(emas_1:emas_12))) %>% 
  ungroup()
```

Create an variable that indicates if all 12 15-day periods have been tallied.

```{r}
ema_initial_pay_approach <- ema_initial_pay_approach %>%
  rowwise() %>% 
  mutate(n_periods = sum(!is.na(c_across(emas_1:emas_12)))) %>% 
  ungroup()
```

```{r}
ema <- ema %>% 
  rowwise() %>% 
  mutate(n_periods = sum(!is.na(c_across(emas_1:emas_12)))) %>% 
  ungroup()
```

Create a combined version of the data set

```{r}
ema_initial_pay_approach <- ema_initial_pay_approach %>% 
  mutate(pay_approach = "Initial")

ema <- ema %>% 
  mutate(pay_approach = "Revised")

ema_combined <- ema_initial_pay_approach %>% 
  bind_rows(ema)
```

Make a long version of the data.

```{r}
ema_combined_long <- ema_combined %>% 
  pivot_longer(
    emas_1:emas_12,
    names_to = "cycle",
    names_prefix = "emas_",
    values_to = "n_completed"
  ) %>% 
  mutate(cycle_f = factor(cycle, 1:12))
```

## Analysis

### Table 9. Ecological Momentary Assessment (EMA) completion metrics by 15-day cycle and payment approach.

NOTES: Rather than do this analysis this way, it might be interesting to graph the median completed by period. According to Jenn (2020-12-14), the important thing to show here is that: 1.) How many EMAs are being completed, 2.) Important piece is to show old payment approach vs. new payment approach, and 3.) Show the bimodal distribution.

Table of emas completed by cycle and payment approach

```{r rows.print=12}
table_9_medians <- ema_combined_long %>% 
  group_by(cycle_f, pay_approach) %>% 
  summarise(
    median = median(n_completed) %>% format(nsmall = 1),
    .groups = "drop"
  ) %>% 
  pivot_wider(
    names_from = "pay_approach",
    values_from = "median"
  )
```

Percent who completed zero emas by cycle and payment approach

```{r rows.print=12}
table_9_percents <- ema_combined_long %>% 
  group_by(cycle_f, pay_approach) %>% 
  summarise(
    rows = n(),
    zeros = sum(n_completed == 0),
    seven_plus = sum(n_completed == 7),
    .groups = "drop"
  ) %>% 
  mutate(
    percent_zero = round(zeros / rows * 100, 1) %>% format(nsmall = 1),
    percent_seven_plus = round(seven_plus / rows * 100, 1) %>% format(nsmall = 1),
    n_percent_zero = paste0(zeros, " (", percent_zero, ")"),
    n_percent_seven_plus = paste0(seven_plus, " (", percent_seven_plus, ")")
  ) %>% 
  select(cycle_f, pay_approach, n_percent_zero, n_percent_seven_plus) %>% 
  pivot_wider(
    names_from = "pay_approach",
    values_from = c("n_percent_zero", "n_percent_seven_plus")
  )
```

Merge medians and percentges together into a single table, and create flextable object.

```{r}
table_9_ft <- table_9_medians %>% 
  left_join(table_9_percents, by = "cycle_f") %>% 
  flextable()
```

Totals

```{r}
ema_combined_long %>% 
  group_by(pay_approach) %>% 
  summarise(
    median = median(n_completed) %>% format(nsmall = 1),
    .groups = "drop"
  ) %>% 
  pivot_wider(
    names_from = "pay_approach",
    values_from = "median"
  )
```

```{r rows.print=12}
ema_combined_long %>% 
  group_by(pay_approach) %>% 
  summarise(
    rows = n(),
    zeros = sum(n_completed == 0),
    seven_plus = sum(n_completed == 7),
    .groups = "drop"
  ) %>% 
  mutate(
    percent_zero = round(zeros / rows * 100, 1) %>% format(nsmall = 1),
    percent_seven_plus = round(seven_plus / rows * 100, 1) %>% format(nsmall = 1),
    n_percent_zero = paste0(zeros, " (", percent_zero, ")"),
    n_percent_seven_plus = paste0(seven_plus, " (", percent_seven_plus, ")")
  ) %>% 
  select(pay_approach, n_percent_zero, n_percent_seven_plus) %>% 
  pivot_wider(
    names_from = "pay_approach",
    values_from = c("n_percent_zero", "n_percent_seven_plus")
  )
```

### Output Word document for easy copy paste

# üìåNOTE

NOTES: Delete all these separate Word documents with tables after you make the big automated report.

```{r}
read_docx() %>%
  body_add_flextable(table_9_ft) %>% 
  print("table_9_2021_05_10.docx")
```

For Table 9, footnote 3 says, ‚ÄúOnly includes PTs who completed the study on or before August 31, 2020.‚Äù I‚Äôm not sure what to do with that. Does that stat ‚Äú37 of 96‚Äù need to be updated or do you want this to continue to reflect PTs who completed the study on or before 2020-08-31? 
The stat needs to be updated to include all participants who completed the study on or before 11/30/20.  

We ran the numbers yesterday through R to get updated numbers and to take a look.  They are in securestor, including the excel sheet where we get the info from the 15-day EMA comp. 
 
For Table 9 footnote, ‚Äú69 app blockers installed to date.‚Äù Where is data on app blocker installation stored? 
We manually count this up from participant 2165. 
 
The current number as of 11/30/20 is 75 total app blockers installed.  

```{r}

```


# Section 8 - Arrests

## Import data

* Had to remove password from Excel sheet before import. Help -> Passwords -> Delete password.
* Had to do a little bit of manual removal of text from dates (i.e., "CURRENTLY IN CUSTODY") in the Excel file.

# üìåDelete

```{r eval=FALSE}
# Don't use
# arrest <- read_excel(
#   "/Users/bradcannell/Desktop/cleanedLink2Care_Arrest_deidentified data_unlocked.xlsx",
#   sheet = "Sheet1",
#   col_names = c(
#     "id", "arrested", "date_1", "charges_1", "date_2", "charges_2", "date_3", 
#     "charges_3", "date_4", "charges_4", "date_5", "charges_5"
#   ),
#   col_types = c(
#     "numeric", "text", rep(c("date", "text"), 5)
#   ),
#   skip = 1
# )
```

```{r}
arrest <- read_excel(
  "/Users/bradcannell/Desktop/Current_Arrest Data_De-identified_2001-2234.xlsx",
  sheet = "Sheet1",
  col_names = c(
    "id", "arrested", "date_baseline", paste("date", 1:5, sep = "_")
  ),
  col_types = c(
    "numeric", "text", rep("date", 6)
  ),
  na = c("", "None"),
  skip = 1
)
```

## Data management

Merge L2C group into the arrest data.

```{r}
arrest <- arrest %>% 
  left_join(
    demographics %>% 
      select(id, group),
    by = "id"
  ) %>% 
  select(id, group, everything())
```

Create factor 

## Analysis

### Table 10. Arrests by treatment arm 12 months after enrollment.

Overall

```{r}
arrest %>% 
  freq_table(arrested) %>% 
  freq_format("n (percent)", digits = 2) %>% 
  select(var, cat, formatted_stats, n_total)
```

By L2C group

```{r}
arrest %>% 
  freq_table(group, arrested) %>% 
  filter(col_cat == "Yes") %>% 
  arrange(desc(n)) %>% 
  freq_format("n (percent_row)", digits = 1) %>% 
  select(row_cat, formatted_stats, n_row)
```


# Section 9 - Bridge Case Session Minutes

## Import data

* This Bridge Session Data is in "/Volumes/Link2Care/Participant Data/Bridge Session Data/Current_Bridge Session Minutes_as of_5-4-21.xlsx". Have to download to local drive first because it's password protected.
* Had to remove password from Excel sheet before import. Help -> Passwords -> Delete password.
* Couldn't remove the password this way, so I copied the information in the sheet and pasted it into a new Excel file.

```{r}
bridge <- read_excel(
  "/Users/bradcannell/Desktop/bridge_2021_05_04.xlsx",
  sheet = "Sheet1",
  col_names = c(
    "id", "baseline_date", "v2_rand_date", "v5_sched_final_visit_date", 
    "date_session", "type", "duration", "flag_ns_v2", "flag_dropped", "notes"
  ),
  col_types = c(
    "numeric", rep("date", 3), "text", rep("numeric", 4), "text"
  ),
  skip = 10
)
```

## Data management

Remove text from date columns and convert to dates.

```{r}
bridge <- bridge %>% 
  mutate(
    date_session = str_remove_all(date_session, "[A-z]|[a-z]"),
    date_session = as.numeric(date_session),
    date_session = as.Date(date_session, origin = "1899-12-30")
  )
```

Remove instructions from "notes" column of rows 1 and 2.

```{r}
bridge[1, "notes"] <- NA_character_
bridge[2, "notes"] <- NA_character_
```

Drop blank rows. In the Excel sheet there were some blank spacer rows.

* `c_across()` doesn't work with columns of different types. So, creating missing data dummy variables.

```{r} 
bridge <- bridge %>%
  # Create missing data dummy variables
  mutate(
    across(
      everything(),
      is.na,
      .names = "{col}_miss"
    )
  ) %>% 
  # Sum missing data dummy variables
  rowwise() %>% 
  mutate(
    n_missing = sum(c_across(ends_with("_miss")))
  ) %>% 
  ungroup() %>% 
  # Drop missing data dummy variables
  select(-ends_with("_miss")) %>% 
  # Drop rows that are missing in every column
  filter(!n_missing == 8)
```

Carry forward id numbers. In the Excel sheet, the id number is only given in the first row of each set of rows for each participant.

```{r}
bridge <- bridge %>%
  # Carry forward id
  fill(id) %>% 
  group_by(id) %>% 
  # Carry forward other variables grouped by id
  fill(baseline_date, v2_rand_date, v5_sched_final_visit_date) %>% 
  ungroup()
```

Create a factor for session type and a dummy variable for case management.

```{r}
bridge <- bridge %>% 
    mutate(
    # Change NA to None for type
    type = if_else(is.na(type), 4, type),
    # Create factor version
    type_f = factor(
      type,
      1:4,
      c("case_management", "crisis_management", "other", "none")
    ),
    # Create dummy variable for case management
    case_management = type_f == "case_management"
  )
```

Merge L2C group into the Bridge data.

```{r}
bridge <- bridge %>%
  left_join(
    demographics %>% 
      select(id, group),
    by = "id"
  ) %>% 
  select(id, group, everything())
```

Create an "other" group to capture groups other than UCM, UCM+SP, and L2C.

```{r}
bridge <- bridge %>%
  mutate(
    group_f = factor(group, c("UCM", "UCM+SP", "L2C")),
    group_f = fct_explicit_na(group_f, na_level = "Other")
  )
```

Remove rows with participants who are missing a V2 randomization date.

* James has a footnote that says, "Excludes participants who missed randomization (V2) date (n=16)." So, I will filter out people who are missing a V2 randomization date.

```{r}
bridge %>% 
  filter(is.na(v2_rand_date)) %>% 
  nrow()
```

There are four participants with a missing date for V2 randomization. They will be removed from the analyses below.

```{r}
bridge <- bridge %>% 
  filter(!is.na(v2_rand_date))
```

Create a dummy variable for 
* "Used at least one session of regular case management."
* "Used at least one session of crisis case management."
* "Used at least one session of other case management."
* "Used no forms of Bridge case management."

```{r}
bridge <- bridge %>%
  group_by(id) %>% 
  mutate(
    row = row_number(),
    total_sessions = sum(type %in% 1:3),
    total_minutes = sum(duration, na.rm = TRUE),
    any_case_management = any(type_f == "case_management"),
    any_crisis_management = any(type_f == "crisis_management"),
    any_other = any(type_f == "other"),
    all_none = all(type_f == "none")
  ) %>% 
  ungroup()
```

Create a "wide" version of the data with one row per participant.

```{r}
bridge_wide <- bridge %>% 
  filter(row == 1)
```

Keep only participants in L2C, UCM, and UCM+SP groups for analysis.

```{r}
bridge <- bridge %>% 
  filter(group_f %in% c("L2C", "UCM", "UCM+SP"))
```

```{r}
bridge_wide <- bridge_wide %>% 
  filter(group_f %in% c("L2C", "UCM", "UCM+SP"))
```

## Analysis

Column totals

```{r}
bridge %>% 
  filter(row == 1) %>% 
  count(group_f) %>% 
  mutate(cum = cumsum(n))
```

### Table 12. Number and percent of participants who used Bridge case management.

This table only needs one row per id.

Include only randomized participants.

```{r}
case_mgmt_vars <- quos(
  any_case_management, any_crisis_management, any_other, all_none
)
```

Overall

```{r}
table_12_overall <- map_df(
  case_mgmt_vars,
  function(x) {
    bridge_wide %>% 
      freq_table({{ x }}) %>% 
      filter(cat == TRUE) %>% 
      freq_format("n (percent)", digits = 1) %>% 
      select(var, formatted_stats)
  }
)
```

By Group

```{r}
table_12_by_group <- map_df(
  case_mgmt_vars,
  function(x) {
    bridge_wide %>% 
      freq_table(group_f, {{ x }}) %>% 
      filter(col_cat == TRUE) %>% 
      select(row_cat, col_var, n, n_row, n_total, percent_row) %>% 
      freq_format("n (percent_row)", digits = 1)
  }
) %>% 
  select(row_cat, col_var, formatted_stats) %>% 
  pivot_wider(
    names_from = "row_cat",
    values_from = "formatted_stats"
  )
```

Merge together and create flextable object.

```{r}
table_12_ft <- table_12_overall %>% 
  left_join(table_12_by_group, by = c("var" = "col_var")) %>% 
  flextable()
```

### Output Word document for easy copy paste

# üìåNOTE

NOTES: Delete all these separate Word documents with tables after you make the big automated report.

```{r}
read_docx() %>%
  body_add_flextable(table_12_ft) %>% 
  print("table_12_2021_05_10.docx")
```

### Table 13. Description of Case Management Sessions and Duration use

Case management of any type

Overall

```{r}
bridge_wide %>% 
  summarise(
    sessions_median = median(total_sessions),
    sessions_min = min(total_sessions),
    sessions_max = max(total_sessions),
    minutes_median = median(total_minutes),
    minutes_min = min(total_minutes),
    minutes_max = max(total_minutes)
  ) %>%
  pivot_longer(
    everything(),
    names_to = c(".value", "measure"),
    names_sep = "_",
    values_to = "stat"
  )
```

```{r}
bridge_wide %>% 
  filter(group_f == "UCM") %>% 
  summarise(
    sessions_median = median(total_sessions),
    sessions_min = min(total_sessions),
    sessions_max = max(total_sessions),
    minutes_median = median(total_minutes),
    minutes_min = min(total_minutes),
    minutes_max = max(total_minutes)
  ) %>%
  pivot_longer(
    everything(),
    names_to = c(".value", "measure"),
    names_sep = "_",
    values_to = "stat"
  )
```

```{r}
bridge_wide %>% 
  filter(group_f == "UCM+SP") %>% 
  summarise(
    sessions_median = median(total_sessions),
    sessions_min = min(total_sessions),
    sessions_max = max(total_sessions),
    minutes_median = median(total_minutes),
    minutes_min = min(total_minutes),
    minutes_max = max(total_minutes)
  ) %>%
  pivot_longer(
    everything(),
    names_to = c(".value", "measure"),
    names_sep = "_",
    values_to = "stat"
  )
```

```{r}
bridge_wide %>% 
  filter(group_f == "L2C") %>% 
  summarise(
    sessions_median = median(total_sessions),
    sessions_min = min(total_sessions),
    sessions_max = max(total_sessions),
    minutes_median = median(total_minutes),
    minutes_min = min(total_minutes),
    minutes_max = max(total_minutes)
  ) %>%
  pivot_longer(
    everything(),
    names_to = c(".value", "measure"),
    names_sep = "_",
    values_to = "stat"
  )
```

```{r}
bridge %>% 
  filter(type_f == "case_management") %>% 
  group_by(id) %>% 
  mutate(
    row = row_number(),
    total_sessions = n(),
    total_minutes = sum(duration)
  ) %>% 
  ungroup() %>% 
  filter(row == 1) %>% 
  summarise(
    sessions_median = median(total_sessions),
    sessions_min = min(total_sessions),
    sessions_max = max(total_sessions),
    minutes_median = median(total_minutes),
    minutes_min = min(total_minutes),
    minutes_max = max(total_minutes)
  ) %>% 
  pivot_longer(
    everything(),
    names_to = c(".value", "measure"),
    names_sep = "_",
    values_to = "stat"
  )
```

```{r}
bridge %>% 
  filter(type_f == "case_management") %>% 
  group_by(id) %>% 
  mutate(
    row = row_number(),
    total_sessions = n(),
    total_minutes = sum(duration)
  ) %>% 
  ungroup() %>% 
  filter(row == 1) %>% 
  group_by(group_f) %>% 
  summarise(
    sessions_median = median(total_sessions),
    sessions_min = min(total_sessions),
    sessions_max = max(total_sessions),
    minutes_median = median(total_minutes),
    minutes_min = min(total_minutes),
    minutes_max = max(total_minutes),
    .groups = "drop"
  ) 
```

```{r}
bridge %>% 
  filter(type_f == "crisis_management") %>% 
  group_by(id) %>% 
  mutate(
    row = row_number(),
    total_sessions = n(),
    total_minutes = sum(duration)
  ) %>% 
  ungroup() %>% 
  filter(row == 1) %>% 
  summarise(
    sessions_median = median(total_sessions),
    sessions_min = min(total_sessions),
    sessions_max = max(total_sessions),
    minutes_median = median(total_minutes, na.rm = TRUE),
    minutes_min = min(total_minutes, na.rm = TRUE),
    minutes_max = max(total_minutes, na.rm = TRUE)
  ) %>% 
  pivot_longer(
    everything(),
    names_to = c(".value", "measure"),
    names_sep = "_",
    values_to = "stat"
  )
```

```{r}
bridge %>% 
  filter(type_f == "crisis_management") %>% 
  group_by(id) %>% 
  mutate(
    row = row_number(),
    total_sessions = n(),
    total_minutes = sum(duration)
  ) %>% 
  ungroup() %>% 
  filter(row == 1) %>% 
  group_by(group_f) %>% 
  summarise(
    sessions_median = median(total_sessions),
    sessions_min = min(total_sessions),
    sessions_max = max(total_sessions),
    minutes_median = median(total_minutes, na.rm = TRUE),
    minutes_min = min(total_minutes, na.rm = TRUE),
    minutes_max = max(total_minutes, na.rm = TRUE),
    .groups = "drop"
  ) 
```

```{r}
bridge %>% 
  filter(type_f == "other") %>% 
  group_by(id) %>% 
  mutate(
    row = row_number(),
    total_sessions = n(),
    total_minutes = sum(duration)
  ) %>% 
  ungroup() %>% 
  filter(row == 1) %>% 
  summarise(
    sessions_median = median(total_sessions),
    sessions_min = min(total_sessions),
    sessions_max = max(total_sessions),
    minutes_median = median(total_minutes, na.rm = TRUE),
    minutes_min = min(total_minutes, na.rm = TRUE),
    minutes_max = max(total_minutes, na.rm = TRUE)
  ) %>% 
  pivot_longer(
    everything(),
    names_to = c(".value", "measure"),
    names_sep = "_",
    values_to = "stat"
  )
```

```{r}
bridge %>% 
  filter(type_f == "other") %>% 
  group_by(id) %>% 
  mutate(
    row = row_number(),
    total_sessions = n(),
    total_minutes = sum(duration)
  ) %>% 
  ungroup() %>% 
  filter(row == 1) %>% 
  group_by(group_f) %>% 
  summarise(
    sessions_median = median(total_sessions),
    sessions_min = min(total_sessions),
    sessions_max = max(total_sessions),
    minutes_median = median(total_minutes, na.rm = TRUE),
    minutes_min = min(total_minutes, na.rm = TRUE),
    minutes_max = max(total_minutes, na.rm = TRUE),
    .groups = "drop"
  ) 
```


# Section 10 - Recruitment

## Import data

# üìåNOTE

Don't need this anymore. I read in the entire master log.

```{r}
# master_log_screened_in <- read_excel(
#   "/Volumes/link2Care/Live Documents/L2C_Master_Log.xlsm",
#   # "/Users/bradcannell/Desktop/L2C_Master_Log.xlsm",
#   sheet = "Screened In",
#   col_names = c(
#     "id", "status", "date_baseline", "date_v2", "date_v3", "date_v4", "date_v5", "group", "name_first", "name_middle", "name_last", "sex", "race", "hispanic", "date_birth", "age", "clincard_id", "n_clincards", "phone_id", "phone_number", "n_phones", "care_manager", "v1", "v2", "v3", "v4", "v5", "v3_r", "v4_r"
#   ),
#   col_types = c(
#     "numeric", "text", "date", rep("text", 4), rep("text", 7), "date", "numeric", "text", "numeric", rep("text", 2), "numeric", "text", rep("numeric", 5), "skip", rep("numeric", 2), rep("skip", 4)
#   ),
#   na = c("", ".", "N/A"),
#   skip = 1
# )
```

## Data management

## Analysis

### Average recruitment by month

```{r}
recruitment <- master_log_screened_in %>% 
  select(date_baseline) %>% 
  mutate(
    covid = if_else(date_baseline < "2020-03-17", "pre", "post")
  )
```

Overall

```{r}
recruitment %>% 
  mutate(year_month = format(date_baseline, "%Y-%b")) %>% 
  count(year_month) %>% 
  mutate(date = ymd(year_month, truncated = 1)) %>% 
  summarise(mean = mean(n))
```

Pre-covid

```{r}
recruitment %>% 
  filter(covid == "pre") %>% 
  mutate(year_month = format(date_baseline, "%Y-%b")) %>% 
  count(year_month) %>% 
  mutate(date = ymd(year_month, truncated = 1)) %>% 
  arrange(date) %>% 
  summarise(mean = mean(n))
```

Post-covid

```{r}
recruitment %>% 
  filter(covid == "post") %>% 
  mutate(year_month = format(date_baseline, "%Y-%b")) %>% 
  count(year_month) %>% 
  mutate(date = ymd(year_month, truncated = 1)) %>% 
  arrange(date) %>% 
  summarise(mean = mean(n))
```

### Figure 2. Recruitment by month.

1. Recruitment began on April 17, 2018 and ended temporarily on March 17, 2020 due to COVID-19 and began again on July 6, 2020
2. Graph does not include participants that screened out during baseline assessment

* Can't just count calls by month because months will be combined across years.
* Can't just paste month and year together because they will be displayed in alphabetical order rather than chronological order.
* Need to create a factor for year and month.

```{r}
baseline_per_month <- master_log_screened_in %>% 
  select(date_baseline) %>% 
  mutate(year_month = format(date_baseline, "%Y-%b")) %>% 
  count(year_month) %>% 
  mutate(date = ymd(year_month, truncated = 1)) %>% 
  # Fill in the missing months and set n to zero.
  complete(
    date = seq.Date(as.Date("2018-04-01"), Sys.Date(), "months"), 
    fill = list(n = 0)
  )
```

```{r}
ggplot(baseline_per_month, aes(date, n, group = 1)) +
  geom_vline(xintercept = as.Date("2020-03-17"), alpha = 0.5, color = "red", linetype = "dashed") +
  geom_vline(xintercept = as.Date("2020-07-06"), alpha = 0.5, color = "red", linetype = "dashed") +
  geom_line() +
  geom_label(aes(label = n)) +
  scale_x_date("Date", date_label = "%Y-%b", 
  # Make sure the x-axis includes the earliest date and today with other breaks
  # coming at 2 month intervals.
  breaks = seq(min(baseline_per_month$date), Sys.Date(), "2 months")
  ) +
  scale_y_continuous("Number of Participants Enrolled") +
  theme_classic() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
```

Save figure for copy and paste into report

```{r}
ggsave("fig_2.jpeg", width = 7, height = 4)
```

### Figure 3. Monthly recruitment stratified by year.

* Can't just count calls by month because months will be combined across years.
* Can't just paste month and year together because they will be displayed in alphabetical order rather than chronological order.
* Need to create a factor for year and month.

```{r}
baseline_per_month_by_year <- master_log_screened_in %>% 
  select(date_baseline) %>% 
  mutate(year_month = format(date_baseline, "%Y-%b")) %>% 
  count(year_month) %>% 
  mutate(date = ymd(year_month, truncated = 1)) %>% 
  # Fill in the missing months and set n to zero.
  complete(
    date = seq.Date(as.Date("2018-04-01"), Sys.Date(), "months"), 
    fill = list(n = 0)
  ) %>% 
  mutate(
    month = format(date, "%b"),
    month_f = factor(month, month.abb),
    year = year(date),
    year_f = factor(year)
  )
```

```{r}
ggplot(baseline_per_month_by_year, aes(month_f, n, group = year_f)) +
  geom_line(aes(color = year_f)) +
  scale_x_discrete("Month") +
  scale_y_continuous("Number of Participants Enrolled") +
  scale_color_manual("Year", values = c("#008744", "#0057e7", "#d62d20", "black")) +
  theme_classic() 
```

Save figure for copy and paste into report

```{r}
ggsave("fig_3.jpeg", width = 7, height = 4)
```

















# üìùCompile into Word Report

2020-12-15:

I ran out of time to actually create the report this way, but I'm saving this code for the future. Keep in mind that you did all of this in an R script for the Sun Study report. You way want to think about why you did that and if it makes sense for this report.

Bookmarks: In Word Document, highlight bookmark, click Insert -> Link -> Bookmark

```{r}
# l2c_report <- read_docx("quarterly_reports/l2c_quarterly_report_template.docx") %>%
#   # Add date updated - pg. 3
#   body_replace_text_at_bkm(
#     bookmark = "date",
#     value = format(Sys.Date(), "%B %d, %Y")
#   )
```

Add number of study participants to page 3 of report.

```{r}
# l2c_report <- l2c_report %>%
#   body_replace_text_at_bkm(
#     bookmark = "n_participants",
#     value = paste0(" ", nrow(demographics))
#   )
```

Add Table 1. Demographic characteristics of all people screened-in.

```{r}
# l2c_report <- l2c_report %>%
#   body_replace_flextable_at_bkm(
#     bookmark = "table_1_ft",
#     value = table_1_ft
#   )
```

## üñ®Output Word document

Update the year and month in the file name dynamically

```{r}
# print(
#   l2c_report, 
#   paste0("quarterly_reports/", Sys.Date() %>% format("%Y_%m"), " L2C Quarterly Report.docx")
# )
```


# üóëClean up

```{r eval=FALSE}
rm(list = ls())
```

```{r echo=FALSE}
sessionInfo()
```











































