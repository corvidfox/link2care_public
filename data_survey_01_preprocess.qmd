---
title: "Step 1 - Preprocessing of DDT, Arrest, and Bridge Session Data"
date: "2022-10-19 <br> Updated: `r Sys.Date()`"
format: pdf
editor: 
  markdown: 
    wrap: sentence
---

# ‚≠êÔ∏èOverview

This file is step 1 in processing the source data from Link2Care (L2C) into a single data set for analysis.

This file is used to perform pre-processing on the Delayed Discount Task (DDT), Arrest Data, and Bridge Session Minutes Data.

These data sources required pre-processing as they were not in a Subject-Visit format.

[Notes on cleaning individual L2C data sets for merging](https://github.com/brad-cannell/link2care_public/wiki/Notes-on-cleaning-individual-L2C-data-sets-for-merging)

## Process Steps

1.  **Pre-process DDT, Arrest, and Bridge Session Minutes data sets so they are compatible with along-format Subject-Visit composite key structure**

2.  Import all source data sets (QDS, REDCap, Master Log, TLFB, DDT, Arrest, Bridge Sessions) to create the variable map

    -   Select variables for inclusion in the final composite data set

    -   Set initial standardization of the variable names for all desired variables in the composite data set

    -   Establish order for the variables in the composite data set

    -   Extract variable label and variable value labels from source data sets to be included in the composite data set

3.  Batch processing of data sets into combined data set

4.  Recreation of calculated variables

    -   Consolidating redundant variables
    
    -   Creation of calculated variables, including labels and addition to the variable map

5.  Post-processing modifications

    -  Finalize desired variable names
    
    -  Flag PHI variables

## Notes

The end goal of our combined data set was to have the Delay Discounted Task data in long format, with each of the five data-collection visits for all subjects represented by a single row (unique combination of Subject ID and Visit), and the Arrest and Bridge Session data in a wide format, where each Subject ID held all of a subject's unique data for any ranges or visits. These parameters were set in the 2023-11-22 meeting with the PIs.

Several of our source data sets were not suitable for processing or merging in their original forms:

-   The Delayed Discount Task (DDT) data was arranged in wide format, where each row contained all collection events for a single subject (unique Subject ID)

    -   This required us to "pivot" the data

-   The Arrest Data and Bridge Session Data was in a semi-long format, such that each row contained a data regarding discrete events (represented by the unique combination of Subject ID and Date)

    -   This required us to perform calculations in order to represent the data in relationship to each unique combination of Subject ID and Visit, with respect to these dates, and then pivot into a 'wide' format.
    
Per discussion with the project PIs on 2023-11-22 and 2023-12-07, date windows for each visit are calculated using the protocol windows from Visit 2's actual attendance date in the Master Log. The PIs request that the Arrest and Bridge Session data be added to the data set so that each row for a subject contains the same data in separate columns.

-   The protocol visit windows are scheduled from V2's actual attendance date, which should be taken from the Master Log

    -   Visit 2 should have occurred within 3 days of Visit 1

    -   Visit 3 should be 1 month after Visit 2: 28-31 days (3 day range)

        -   30 ¬± 2 days

    -   Visit 4 should be 3 months after Visit 3: 89-92 days (3 day range)

        -   90 ¬± 2 days

    -   Visit 5 should be 6 months after Visit 2: 181-184 days (3 day range)
    
        -   182 ¬± 2 days
        
    -   Any records outside of the target windows should be excluded.
    
-   The Arrest Data was to begin on V2's attendance date, and run for 1 year after. 

    -   Total number of arrests for the V2-V3, V3-V4, V4-V5, V2-V5, V5-1 year, V2-V5, and V2-1 year windows
    
    -   The plan should result in 8 columns of data: 1 for the subject ID, the 7 for the visit window results
    
    -   Minor point-fixes are required for several records that have date typos, per PI evaluation
    
-   The Bridge Session data was to begin on V2's attendance date, and run for 6 months (V5's protocol)

    -   All items to be calculated for V2-V3, V3-V4, V4-V5, and V2-5 windows; items should be calculated as an aggregrate (any type of visit) and broken down by type ("Regular", "Crisis", "Other")
    
        -   Number of sessions, number of minutes, and average minutes per session
    
    -   The plan should result in 49 columns: 1 for the subject ID, and 48 for the visit window results (4 windows * 4 types * 3 columns)
    
# üì¶Load packages & Functions

```{r, message=FALSE, warning=FALSE}
library(dplyr, warn.conflicts = FALSE)
library(purrr, warn.conflicts = FALSE)
library(haven, warn.conflicts = FALSE)
library(here, warn.conflicts = FALSE)
library(stringr, warn.conflicts = FALSE)
library(lubridate, warn.conflicts = FALSE)
library(readxl, warn.conflicts = FALSE)
library(openxlsx, warn.conflicts = FALSE)
library(readr, warn.conflicts = FALSE)
library(tidyverse, warn.conflicts = FALSE)
```

```{r}
source(here("R", "data_mod_check.R"))
source(here("R", "data_cols.R"))
# Remove Unnecessary Columns, for memory management
rm(redcap_cols)
rm(qds_col_list)
rm(tlfb_cols)
```

# Master Log

## üì• Import the Data

We imported the Master Log data, manually assigning column names and types.

The Master Log was our most reliable source of the Date of each Visit for each Subject, which was useful for converting Subject-Date records into a Subject-Visit format.

```{r}
master_log_path <- here("data", "master_log", "master_log.xlsx")
```

Import the data.
Check the most recent file modification dates and print for user when this file is being sourced.

```{r}
master_log <- readxl::read_excel(
  master_log_path, 
  sheet = "Screened In",
  col_names = c(
    "id", "baseline_dt",
    "v2_sch", "v2_dt", "v2_late", "v2_noshow",
    "v3_sch", "v3_dt", "v3_late", "v3_noshow",
    "v4_sch", "v4_dt", "v4_late", "v4_noshow",
    "v5_sch", "v5_dt", "v5_late", "v5_noshow",
    "group"
    ),
  col_types = c(
    "numeric", "skip", "date", "skip",  
    "date", "date", "text", "text", "skip",
    "date", "date", "text", "text", "skip",
    "date", "date", "text", "text", "skip",
    "date", "date", "text", "text",
    "text", rep("skip", 31)
    ),
  skip = 1
  ) |>
  # Coerce group to factor
  dplyr::mutate(
    group = factor(group, levels = c('UCM', 'UCM+SP', 'L2C'), ordered = TRUE)
  ) |>
  # Remove empty rows
  dplyr::filter(!is.na(id))

# Print a message for when this file is being sourced
cat(
  paste0(Sys.Date(), ":"),
  "Master log imported with", nrow(master_log), "rows and", ncol(master_log),
  "columns.\n"
)

# Check the most recent file modification dates and print for user when this
# file is being sourced.

cat(
      "Master log last modified on OneDrive", 
      as.character(file.info(master_log_path)$mtime), "\n"
    )

# 2023-12-11: Master log imported with 442 rows and 19 columns.
# Master log last modified on OneDrive 2023-09-28 11:52:59
```

### Data Check: Changes

We checked for changes to the source data set since this file was last modified.

```{r}
# Inputs last modified: 2023-12-11

data_mod_check(
  'df' = master_log,
  'df_path_str' = master_log_path,
  'orig_path_str' = here("data", "master_log", "master_log.xlsx"),
  'mod_dt' = '2023-09-28 11:52:59 CDT',
  'num_rows' = 442,
  'num_cols' = 19,
  'col_names' = c(
    "id", "baseline_dt",
    "v2_sch", "v2_dt", "v2_late", "v2_noshow",
    "v3_sch", "v3_dt", "v3_late", "v3_noshow",
    "v4_sch", "v4_dt", "v4_late", "v4_noshow",
    "v5_sch", "v5_dt", "v5_late", "v5_noshow",
    "group"
    )
  )
# TRUE
```

We purged the import path for memory management.

```{r}
rm(master_log_path)
```

## Creating Date Windows and Subject-Visit Filter Keys

We calculated the date windows applicable to each visit. Per discussion with the project PIs on 2023-11-22 and 2023-12-07, windows are calculated using the protocol windows from Visit 2's actual attendance date in the Master Log. For subjects that did not attend V2, we utilized the V2 Scheduled Date in the Master Log. We accounted for weekends, by rolling the protocol dates of Sunday forward to Monday, and Saturday backward to Friday. The end date was calculated as 1 year after the V2 attendance date. We also modified the No-Show column for each visit, to flag if a subject did not have an attendance date for a visit.


```{r}
visit_windows <- master_log |>
  dplyr::mutate(
    # V3
    v3_protocol = dplyr::if_else(
      !is.na(v2_dt), 
      v2_dt + lubridate::ddays(30), 
      v2_sch + lubridate::ddays(30)
      ),
    v3_protocol_wkd = dplyr::case_when(
      lubridate::wday(v3_protocol) == 1 ~ v3_protocol + lubridate::ddays(1),
      lubridate::wday(v3_protocol) == 7 ~ v3_protocol - lubridate::ddays(1),
      TRUE ~ v3_protocol
      ),
    # V4
    v4_protocol = dplyr::if_else(
      !is.na(v2_dt), 
      v2_dt + lubridate::ddays(90), 
      v2_sch + lubridate::ddays(90)
      ),
    v4_protocol_wkd = dplyr::case_when(
      lubridate::wday(v4_protocol) == 1 ~ v4_protocol + lubridate::ddays(1),
      lubridate::wday(v4_protocol) == 7 ~ v4_protocol - lubridate::ddays(1),
      TRUE ~ v4_protocol
      ),
    # V5
    v5_protocol = dplyr::if_else(
      !is.na(v2_dt), 
      v2_dt + lubridate::ddays(182), 
      v2_sch + lubridate::ddays(182)
      ),
    v5_protocol_wkd = dplyr::case_when(
      lubridate::wday(v5_protocol) == 1 ~ v5_protocol + lubridate::ddays(1),
      lubridate::wday(v5_protocol) == 7 ~ v5_protocol - lubridate::ddays(1),
      TRUE ~ v5_protocol
      ),
    # End
    end_protocol = dplyr::if_else(
      !is.na(v2_dt), 
      v2_dt + lubridate::ddays(365), 
      v2_sch + lubridate::ddays(365)
      ),
    end_protocol_wkd = dplyr::case_when(
          lubridate::wday(end_protocol) == 1 ~ 
            end_protocol + lubridate::ddays(1),
          lubridate::wday(end_protocol) == 7 ~
            end_protocol - lubridate::ddays(1),
          TRUE ~ end_protocol
          )
    ) |>
  dplyr::mutate(
    v2_noshow = ifelse(is.na(v2_dt), TRUE, FALSE),
    v3_noshow = ifelse(is.na(v3_dt), TRUE, FALSE),
    v4_noshow = ifelse(is.na(v4_dt), TRUE, FALSE),
    v5_noshow = ifelse(is.na(v5_dt), TRUE, FALSE)
  )
```

We then calculated our visit windows, and extracted our desired columns (id, protocol dates, and visit windows). For the V5-1 year visit dates, the start date and end date were advanced by 1 hour, to allow any visits on the actual V5 protocol date to be excluded and any on the actual end date to be included. For the V4-V5 and V2-V5 study windows, the V5 end date was similarly advanced by 1 hour to allow visits on the actual V5 protocol date to be included.

We added 1 hour to the end time of the Visit 5 windows (and advanced the beginning of the end windows 1 hour), to allow any visits on 

```{r}
visit_windows <- visit_windows |>
    dplyr::rowwise() |>
    dplyr::mutate(
      # V2 window is from Baseline Actual to V2 Actual
      # If V2 was not attended, use V2 Scheduled
        v2_window = dplyr::case_when(
          (is.na(v2_dt)) ~ lubridate::interval(
            start = baseline_dt, end = v2_sch
            ),
          (!is.na(v2_dt) & !is.na(baseline_dt)) ~ 
              lubridate::interval(start = baseline_dt, end = v2_dt),
          TRUE ~ NA
        ),
      # V3 window is from V2 actual to V3 protocol (30 days), accounting for
      # weekends
      # If V2 was not attended, use V2 scheduled
        v3_window = dplyr::case_when(
          (is.na(v2_dt)) ~ lubridate::interval(v2_sch, v3_protocol_wkd),
          (!is.na(v3_protocol_wkd) & !is.na(v2_dt)) ~
            lubridate::interval(v2_dt, v3_protocol_wkd),
          TRUE ~ NA
        ),
      # V4 window is from V3 protocol (30 days) to V4 protocol (60 days), 
      # accounting for weekends
        v4_window = dplyr::case_when(
          (!is.na(v4_protocol_wkd) & !is.na(v3_protocol_wkd)) ~
            lubridate::interval(v3_protocol_wkd, v4_protocol_wkd),
          TRUE ~ NA
        ),
      # V5 window is from V4 protocol (60 days) to V5 protocol (182 days), 
      # accounting for weekends. One hour is added to the end of the V5 
      # protocol date, to allow visits on the actual date to be included.
        v5_window = dplyr::case_when(
          (!is.na(v5_protocol_wkd) & !is.na(v4_protocol_wkd)) ~
            lubridate::interval(
              v4_protocol_wkd, v5_protocol_wkd + lubridate::dhours(1)
              ),
          TRUE ~ NA
        ),
      # The end window is from V5 Actual to 1 year protocol end date,
      # accounting for weekends. One hour is added to the end of the 1 year 
      # protocol end date and beginning of the V5 protocol date, to allow 
      # records on the actual V5 date to be excluded and any on the end date
      # to be included.
        end_window = dplyr::case_when(
          (!is.na(v5_protocol_wkd) & !is.na(end_protocol_wkd)) ~
            lubridate::interval(
              v5_protocol_wkd + lubridate::dhours(1), 
              end_protocol_wkd + lubridate::dhours(1)
              ),
          TRUE ~ NA
        ),      
      # The study period window is from V2 Actual to V5 protocol (182 days),
      # accounting for weekends. One hour is added to the end of the V5 
      # protocol date, to allow records on the actual date to be included.
      # If V2 was not attended, use V2 scheduled
        study_window = dplyr::case_when(
          (is.na(v2_dt)) ~ 
            lubridate::interval(
              v2_sch, v5_protocol_wkd + lubridate::dhours(1)
              ),
          (!is.na(v5_protocol_wkd) & !is.na(v2_dt)) ~
            lubridate::interval(
              v2_dt, v5_protocol_wkd + lubridate::dhours(1)
              ),
          TRUE ~ NA
        ),
      # The full window is from V2 Actual to 1 year protocol end date,
      # accounting for weekends. One hour is added to the end of the 1 year 
      # protocol end date, to allow records on the actual date to be included.
      # If V2 was not attended, use V2 scheduled
        full_window = dplyr::case_when(
          (is.na(v2_dt)) ~ 
            lubridate::interval(
              v2_sch, end_protocol_wkd + lubridate::dhours(1)
              ),
          (!is.na(v2_dt) & !is.na(end_protocol_wkd)) ~
            lubridate::interval(
              v2_dt, end_protocol_wkd + lubridate::dhours(1)
              ),
          TRUE ~ NA
        )
      ) |>
    dplyr::ungroup() |>
  dplyr::select(
    id, v2_noshow, v3_noshow, v4_noshow, v5_noshow,
    baseline_dt, v2_dt, v3_protocol_wkd, v4_protocol_wkd, v5_protocol_wkd, 
    end_protocol_wkd, 
    v2_window, v3_window, v4_window, v5_window, end_window, 
    study_window, full_window
    )
```

We then purged the originally imported Master Log data set for memory management.

```{r}
rm(master_log)
```

### üíæ Save the Date Window Data

We set our desired output paths

```{r}
# RDS version
rds_path <- here("data", "master_log", "ml_protocol_dates.rds")

# MB also wants an SPSS version
spss_path <- here("data", "master_log", "ml_protocol_dates.sav")
```

We performed a check for any changes to the data since it was last saved in RDS format.

```{r}
# Inputs last modified: 2023-12-11

data_mod_check(
  'df' = visit_windows,
  'df_path_str' = rds_path,
  'orig_path_str' = here("data", "master_log", "ml_protocol_dates.rds"),
  'mod_dt' = NA,
  'num_rows' = 442,
  'num_cols' = 18,
  'col_names' = visit_window_cols
  )
# TRUE
```

We exported our files.

```{r}
# RDS version
readr::write_rds(visit_windows, rds_path)

# MB also wants an SPSS version
haven::write_sav(visit_windows, spss_path)
```

Print a message for when this file is saved.

```{r}
cat(
  paste0(Sys.Date(), ":"),
  "Visit Dates and Windows data saved to", rds_path, " and ", spss_path
)
```

Purge path variables and exported data to avoid potential errors in later processing.

```{r}
rm(rds_path)
rm(spss_path)
rm(visit_window_cols)
```

# Processing Data Frames

## Delayed Discount Task (DDT)

The Delayed Discount Task (DDT) data primarily required pivoting from a wide format into a long format.

### üì• Import the Data

All Delayed Discount Task (DDT) section data was initially processed with SPSS.

```{r}
ddt_spss_path <- here("data", "ddt", "L2C_DDT_Database_1.sav")
```

Import the data.
Check the most recent file modification dates and print for user when this file is being sourced.

```{r, message=FALSE}
ddt <- haven::read_sav(ddt_spss_path)

# Print a message for when this file is being sourced
cat(
  paste0(Sys.Date(), ":"),
  "DDT imported with", nrow(ddt), "rows and", ncol(ddt), "columns.\n"
)

# Check the most recent file modification dates and print for user when this
# file is being sourced.

cat(
      "DDT data last modified on OneDrive", 
      as.character(file.info(ddt_spss_path)$mtime), "\n"
    )

# 2023-12-11: DDT imported with 442 rows and 9 columns.
# DDT data last modified on OneDrive 2023-08-25 10:44:11 
```

#### Data Check: Changes

We checked for changes to the source data set since this file was last modified.

```{r}
# Inputs last modified: 2023-12-11

data_mod_check(
  'df' = ddt,
  'df_path_str' = ddt_spss_path,
  'orig_path_str' = here("data", "ddt", "L2C_DDT_Database_1.sav"),
  'mod_dt' = '2023-08-25 10:44:11 CDT',
  'num_rows' = 442,
  'num_cols' = 9,
  'col_names' = ddt_orig_cols
  )
# TRUE
```

We purged the import path for memory management.

```{r}
rm(ddt_spss_path)
rm(ddt_orig_cols)
```


### Processing

We inspected our column names and classes, to ensure compatibility in the pivot.
We identified that several of our columns were of the "character" class, which would result in non-compatibility in the pivot.

```{r}
ddt |> 
    dplyr::summarise_all(class) |> 
    tidyr::gather(variable, class)
```

Further inspection revealed the cause: the DDT data had a significant number of missing values represented by the character "." As every column should only contain numeric values, we could convert the columns so that these "." values would be coerced into missing (`NA`) values.
We performed this modification.

```{r}
ddt <- ddt |>
  dplyr::mutate(dplyr::across(everything(), as.numeric))

# Warning: There were 6 warnings in `mutate()`.
# The first warning was:
# ‚Ñπ In argument: `across(everything(), as.numeric)`.
# Caused by warning:
# ! NAs introduced by coercion
# ‚Ñπ Run dplyr::last_dplyr_warnings() to see the 5 remaining warnings.
```

We pivoted our revised DDT data into our desired format.

```{r}
ddt <- ddt |> 
  tidyr::pivot_longer(
    K_V1:ED50_V5,
    cols_vary = "fastest",
    names_to = c(".value", "visit"),
    names_pattern = "(K|ED50)_V([1-5])"
    )
```

We gave labels to each of these new variables.

```{r}
attributes(ddt$Subject)$label <- "Subject ID Number (eligible)"
attributes(ddt$visit)$label <- "Which visit is the participant completing?"
attributes(ddt$K)$label <- "DDT K"
attributes(ddt$ED50)$label <- "DDT ED50"
```

### üíæ Save the Pivoted DDT Data

We set our desired output paths
```{r}
# RDS version
rds_path <- here("data", "ddt", "l2c_ddt_database_2_long.rds")

# MB also wants an SPSS version
spss_path <- here("data", "ddt", "l2c_ddt_database_2_long.sav")
```

We performed a check for any changes to the data since it was last saved in RDS format.

```{r}
# Inputs last modified: 2023-12-11

data_mod_check(
  'df' = ddt,
  'df_path_str' = rds_path,
  'orig_path_str' = here("data", "ddt", "l2c_ddt_database_2_long.rds"),
  'mod_dt' = NA,
  'num_rows' = 1768,
  'num_cols' = 4,
  'col_names' = ddt_pivot_cols
  )
# TRUE
```

And we performed a check for any changes to the data since it was last saved in SPSS format.

```{r}
# Inputs last modified: 2023-12-11

data_mod_check(
  'df' = ddt,
  'df_path_str' = spss_path,
  'orig_path_str' = here("data", "ddt", "l2c_ddt_database_2_long.sav"),
  'mod_dt' = NA,
  'num_rows' = 1768,
  'num_cols' = 4,
  'col_names' = ddt_pivot_cols
  )
# TRUE
```

We exported our files.

```{r}
# RDS version
readr::write_rds(ddt, rds_path)

# MB also wants an SPSS version
haven::write_sav(ddt, spss_path)
```

Print a message for when this file is saved.

```{r}
cat(
  paste0(Sys.Date(), ":"),
  "Pivoted DDT data saved to", rds_path, " and ", spss_path
)
```

Purge path variables and exported data to avoid potential errors in later processing.

```{r}
rm(rds_path)
rm(spss_path)
rm(ddt)
rm(ddt_pivot_cols)
```

## Arrest Data

The Arrest Data required calculation of variables in order to convert the rows collecting arrest dates for each subject into counts by window. In order to ensure the most accurate dates for the data collection events for each subject, the Master Log's record of each visit's date window was utilized.

### üì• Import the Data

The arrest data was securely transmitted by Dr. Gonzalez as an Excel file, which was originally stored on OneDrive in Participant Data \> Arrest Data Requests.

```{r}
arrest_path <- here("data", "arrest", "arrest.xlsx")
```

Import the data.
Check the most recent file modification dates and print for user when this file is being sourced.

```{r}
arrest_data <- readxl::read_excel( 
  arrest_path,
  sheet = "Sheet1",
  col_names = c(
    "id", "arrested_during_followup", "baseline_date", 
    paste("arrested_date",1:12, sep = "_"),  "arrested_num_summary"
  ),
  col_types = c(
    "numeric", "text", "date", 
    rep("date", 12), "numeric"
  ),
  na = c("", "None"),
  skip = 1
) |>
  # Remove empty rows
dplyr::filter(!is.na(id))

# Print a message for when this file is being sourced

cat(
  stringr::str_extract(arrest_path, "([^/]+$)"),
  "last modified on UTHealth server:",
  as.character(file.info(arrest_path)$mtime), "\n",
  paste(Sys.Date(), ":"),
  "Arrest data imported with", nrow(arrest_data), "rows and", 
  ncol(arrest_data), "columns.\n"
)
# arrest.xlsx last modified on UTHealth server: 2023-12-08 15:50:31
# 2023-12-08 : Arrest data imported with 442 rows and 16 columns.
```

#### Data Check: Changes

We checked for changes to the source data set since this file was last modified.

```{r}
# Inputs last modified: 2023-12-08

data_mod_check(
  'df' = arrest_data,
  'df_path_str' = arrest_path,
  'orig_path_str' = here("data", "arrest", "arrest.xlsx"),
  'mod_dt' = '2023-12-08 15:50:31  CDT',
  'num_rows' = 442,
  'num_cols' = 16,
  'col_names' = arrest_orig_cols
  )
# TRUE
```

We purged the file path for memory management.

```{r}
rm(arrest_path)
rm(arrest_orig_cols)
```

### Processing

We eliminated subjects that were missing a baseline date to eliminate any extra rows of empty values.

We also converted the variable `arrested_during_followup`, which contained a "Yes" or "No" value to indicate if a subject had any arrest records in the file, to a logical boolean.

```{r}
arrest_data <- arrest_data |>
  dplyr::filter(!is.na(baseline_date)) |>
  dplyr::mutate(arrested_during_followup = dplyr::case_when(
      toupper(arrested_during_followup) == "YES" ~ TRUE,
      toupper(arrested_during_followup) == "NO" ~ FALSE,
      TRUE ~ NA
    )
  )
```

We combined our Arrest Data with the Visit Windows from the Master Log by subject to allow processing by Subject.

```{r}
arrest_data <- dplyr::left_join(arrest_data, visit_windows, by = "id")
```

We then converted the arrest dates to indicators for each potential visit window, calculated the total number of arrests for each subject both within each of the potential windows. We also recalculated the boolean/logical indication of if a subject had an arrest reported. We then isolated our Subject ID, and the newly created count variables arrested boolean/logical variables.

```{r}
arrest_data <- arrest_data |>
  # Drop "baseline_date"
  dplyr::select(-baseline_date) |>
  # Point-fix
  dplyr::mutate(
    arrested_date_1 = if_else(
      id == 2285, 
      arrested_date_1 %m-% lubridate::years(1), 
      arrested_date_1)
  ) |>
  dplyr::mutate(
    # Calculate the window in which each arrest occurred
    dplyr::across(all_of(starts_with("arrested_date_")),
           ~dplyr::case_when(
               is.na(cur_column()) ~ 
                 NA,
               # If within a window, assign the value for that
               ((!is.na(cur_column()) & !is.na(end_window)) & 
                  (. %within% end_window)) ~
                 "6",
               ((!is.na(cur_column()) & !is.na(v5_window)) & 
                  (. %within% v5_window)) ~
                 "5",
               ((!is.na(cur_column()) & !is.na(v4_window)) & 
                  (. %within% v4_window)) ~
                 "4",
               ((!is.na(cur_column()) & !is.na(v3_window)) & 
                  (. %within% v3_window)) ~
                 "3",
               ((!is.na(cur_column()) & !is.na(v2_window)) & 
                  (. %within% v2_window)) ~
                 "2",
               TRUE ~ NA
              )
           )
    ) |>
  dplyr::rowwise()|>
  # Calculate total number of arrests within each window
  dplyr::mutate(
    v2_count = sum(
      dplyr::c_across(arrested_date_1:arrested_date_12) == "2", 
      na.rm = TRUE
      ),
    v3_count = sum(
      dplyr::c_across(arrested_date_1:arrested_date_12) == "3", 
      na.rm = TRUE
      ),
    v4_count = sum(
      dplyr::c_across(arrested_date_1:arrested_date_12) == "4", 
      na.rm = TRUE
      ),
    v5_count = sum(
      dplyr::c_across(arrested_date_1:arrested_date_12) == "5", 
      na.rm = TRUE
      ),
    end_count = sum(
      dplyr::c_across(arrested_date_1:arrested_date_12) == "6", 
      na.rm = TRUE
      )
    ) |>
  dplyr::mutate(
  # Calculate the number of arrests that occurred in the study period (V2-V5)
    v2_v5_total = sum(dplyr::c_across(v2_count:v5_count)),
  # Calculate the number of arrests that occurred in the follow-up period 
  # (V2-end)
    v2_end_total = sum(dplyr::c_across(v2_count:end_count))
  ) |>
  dplyr::ungroup() |>
  # Select only id, "arrested_during_followup", and count variables
  dplyr::select(
    id, all_of(contains(c("count", "total"))), arrested_during_followup
    ) |>
  dplyr::mutate(
  # Calculate a Boolean/Logical Flag, if subject arrested from V2-V5
    arrested_during_study = ifelse(v2_v5_total > 0, TRUE, FALSE),
  # Calculate a Boolean/Logical Flag, if subject arrested from V2-1year
    arrested_during_followup = if_else(v2_end_total > 0, TRUE, FALSE)
  ) |>
  dplyr::relocate(id, arrested_during_study, arrested_during_followup) 
```

We gave labels to each of these new variables.

```{r}
attributes(arrest_data$id)$label <- "Subject ID Number (eligible)"
attributes(arrest_data$arrested_during_study)$label <- paste0(
  "Was the subject ever arrested during the study period? (V2-V5 protocol)"
  )
attributes(arrest_data$arrested_during_followup)$label <- paste0(c(
  "Was the subject ever arrested during the followup period? ",
  "(V2-1 year protocol)"
  ))
attributes(arrest_data$v2_count)$label <- paste0(
  "Number of recorded arrests between Baseline and V2"
  )
attributes(arrest_data$v3_count)$label <- paste0(
  "Number of recorded arrests between V2 and V3 protocol dates"
  )
attributes(arrest_data$v4_count)$label <- paste0(
  "Number of recorded arrests between V3 and V4 protocol dates"
  )
attributes(arrest_data$v5_count)$label <- paste0(
  "Number of recorded arrests between V4 and V5 protocol dates"
  )
attributes(arrest_data$end_count)$label <- paste0(
  "Number of recorded arrests between V5 and 1-year protocol dates"
  )
attributes(arrest_data$v2_v5_total)$label <- paste0(
  "Number of recorded arrests during the study period (V2-V5 protocol)"
  )
attributes(arrest_data$v2_end_total)$label <- paste0(
  "Number of recorded arrests during the follow-up period (V2-1 year protocol)"
  )

```

### üíæ Save the Processed Arrest Data

We set our desired output paths
```{r}
# RDS version
rds_path <- here("data", "arrest", "arrest_1.rds") 

# MB also wants an SPSS version
spss_path <- here("data", "arrest", "arrest_1.sav")
```

We performed a check for any changes to the data since it was last saved in RDS format.

```{r}
# Inputs last modified: 2023-12-11

data_mod_check(
  'df' = arrest_data,
  'df_path_str' = rds_path,
  'orig_path_str' = here("data", "arrest", "arrest_1.rds"),
  'mod_dt' = NA,
  'num_rows' = 442,
  'num_cols' = 10,
  'col_names' = arrest_proc_cols
  )
# TRUE
```

And we performed a check for any changes to the data since it was last saved in SPSS format.

```{r}
# Inputs last modified: 2023-12-11

data_mod_check(
  'df' = arrest_data,
  'df_path_str' = spss_path,
  'orig_path_str' = here("data", "arrest", "arrest_1.sav"),
  'mod_dt' = NA,
  'num_rows' = 442,
  'num_cols' = 10,
  'col_names' = arrest_proc_cols
  )
# TRUE
```

We exported our files.

```{r}
# RDS version
readr::write_rds(arrest_data, rds_path)

# MB also wants an SPSS version
haven::write_sav(arrest_data, spss_path)
```

Print a message for when this file is saved.

```{r}
cat(
  paste0(Sys.Date(), ":"),
  "Processed Arrest Data saved to", rds_path, " and ", spss_path
)
```

Purge path variables and exported data to avoid potential errors in later processing.

```{r}
rm(rds_path)
rm(spss_path)
rm(arrest_data)
rm(arrest_proc_cols)
```

## Bridge Session Minutes

The Bridge Session data required calculation of variables in order to convert the long-wise list collecting session dates, types, and minutes for each session for each subject into counts and summations by window. In order to ensure the most accurate dates for the data collection events for each subject, the Master Log's record of each visit's date window was utilized.

### üì• Import the Data

The Bridge Session data was provided in an Excel file and securely stored on UTHealth servers.

```{r}
bridge_path <- here(
  "data", "bridge_session_data", "bridge_session_minutes.xlsx"
  )
```

Import the data.
Check the most recent file modification dates and print for user when this file is being sourced.

```{r}
bridge_data <- readxl::read_excel(
  bridge_path,
  sheet = "Sheet1",
  col_names = c(
    "subject", "bridge_baseline_date", "bridge_v2_rand_date", 
    "bridge_v5_sched_final_visit_date", "bridge_date_session", "bridge_type", 
    "bridge_duration", "bridge_flag_ns_v2", "bridge_flag_dropped", 
    "bridge_notes"
  ),
  col_types = c(
    "numeric", rep("date", 3), "text", rep("numeric", 4), "text"
  ),
  na = c("", ".", "None"),
  skip = 10
)

# Print a message for when this file is being sourced

cat(
  stringr::str_extract(bridge_path, "([^/]+$)"),
  "last modified on UTHealth server:",
  as.character(file.info(bridge_path)$mtime), "\n",
  paste(Sys.Date(), ":"),
  "Bridge Session data imported with", nrow(bridge_data), "rows and", 
  ncol(bridge_data), "columns.\n"
)

# bridge_session_minutes.xlsx last modified on UTHealth server: 
# 2023-08-25 10:43:48 
#  2023-12-11 : Bridge Session data imported with 4377 rows and 10 columns.
```

We also had an Excel sheet of point-fixes, established in a meeting of all PIs to review potential typographical errors in the document on 2023-11-22. Nearly all fixes were due to single digit year typos (i.e. "2001" vs "2021", "12/01/2019" vs "12/01/2018") determined by examining trends in the session record data for each subject, which was recorded chronologically.

```{r}
point_fix_path <- here(
  "data", "bridge_session_data", "bridge_point_fixes.xlsx"
  )
```

Import the data.
Check the most recent file modification dates and print for user when this file is being sourced.

```{r}
bridge_fixes <- readxl::read_excel(
  point_fix_path,
  sheet = "Sheet1",
  col_names = c(
    'subject', 'original_date', 'new_date'
  ),
  col_types = c(
    "numeric", "date", "date"
  ),
  na = c("", ".", "None"),
  skip = 1
)

# Print a message for when this file is being sourced

cat(
  stringr::str_extract(point_fix_path, "([^/]+$)"),
  "last modified on UTHealth server:",
  as.character(file.info(point_fix_path)$mtime), "\n",
  paste(Sys.Date(), ":"),
  "Bridge Session point-fix data imported with", nrow(bridge_fixes), 
  "rows and", ncol(bridge_fixes), "columns.\n"
)

# bridge_point_fixes.xlsx last modified on UTHealth server: 2023-12-08 15:17:06 
#  2023-12-11 : Bridge Session point-fix data imported with 25 rows and 
#  3 columns.
```

#### Data Check: Changes

We checked for changes to the source data set since this file was last modified.

```{r}
# Inputs last modified: 2023-12-11

data_mod_check(
  'df' = bridge_data,
  'df_path_str' = bridge_path,
  'orig_path_str' = here(
      "data", "bridge_session_data", "bridge_session_minutes.xlsx"
      ),
  'mod_dt' = '2023-08-25 10:43:48 CDT',
  'num_rows' = 4377,
  'num_cols' = 10,
  'col_names' = bridge_orig_cols
  )
# TRUE
```

We checked for changes to the point-fix data set since this file was last modified.

```{r}
# Inputs last modified: 2023-12-11

data_mod_check(
  'df' = bridge_fixes,
  'df_path_str' = point_fix_path,
  'orig_path_str' = here(
      "data", "bridge_session_data", "bridge_point_fixes.xlsx"
      ),
  'mod_dt' = '2023-12-08 15:17:06 CDT',
  'num_rows' = 25,
  'num_cols' = 3,
  'col_names' = c(
      'subject', 'original_date', 'new_date'
      )
  )
# TRUE
```

We purged the file path for memory management.

```{r}
rm(bridge_path)
rm(point_fix_path)
rm(bridge_orig_cols)
```

### Modification of Data to Facilitate R Processing

The Bridge Session data was written in a format which was favorable for human legibility, but poor for import and machine-legibility in processing.

The column `bridge_date_session` contained text values instead of dates for several subjects, which prohibited importing the column as a date-class column. We replaced these string values with missing (`NA`) values, converted the column to a numeric in order to force any remaining string values into missing (`NA`) values, and finally converted the variable into a date-class column that accounts for Excel's format of date storage.

```{r}
bridge_data <- bridge_data |>
  dplyr::mutate(
    bridge_date_session = dplyr::if_else(
      stringr::str_detect(bridge_date_session, "[A-Z]|[a-z]"), 
      NA_character_, bridge_date_session
    ),
    bridge_date_session = as.numeric(bridge_date_session),
    bridge_date_session = as.Date(bridge_date_session, origin = "1899-12-30")
  )

# Warning: There was 1 warning in `dplyr::mutate()`.
# ‚Ñπ In argument: `bridge_date_session = as.numeric(bridge_date_session)`.
# Caused by warning:
# ! NAs introduced by coercion
```

The first two rows within the `bridge_notes` column contained instructions for manual use of the Excel file.
We converted this data into missing (`NA`) values.

```{r}
bridge_data[1, "bridge_notes"] <- NA_character_
bridge_data[2, "bridge_notes"] <- NA_character_
```

There were several blank dummy rows that were used to increase human legibility of the original Excel file, which needed to be removed prior to processing. Since `c_across()` was unable to work with columns of different types, dummy variables were created to indicate which rows within each column only contained missing values. The total number was summed for each row, allowing the empty rows to be properly identified and dropped. The dummy variables were then dropped.

```{r}
bridge_data <- bridge_data |>
  # Create missing data dummy variables
  dplyr::mutate(
    dplyr::across(
      everything(),
      is.na,
      .names = "{col}_miss"
    )
  ) |> 
  # Sum missing data dummy variables
  dplyr::rowwise() |> 
  dplyr::mutate(
    n_missing = sum(dplyr::c_across(ends_with("_miss")))
  ) |> 
  dplyr::ungroup() |> 
  # Drop missing data dummy variables
  dplyr::select(-ends_with("_miss")) |> 
  # Drop rows that are missing in every column
  dplyr::filter(!n_missing == ncol(bridge_data)) |>
  # Drop the count of missing variables
  dplyr::select(-n_missing)
```

In the Excel sheet the Subject ID number, baseline date, randomization date, and final visit schedule date were only listed in the first set of rows for each participant. While this increased human-legibility in Excel, these values had to be carried forward in order to process the file with code.

```{r}
bridge_data <- bridge_data |>
  # Carry forward id
  fill(subject) |> 
  group_by(subject) |> 
  # Carry forward other variables grouped by id
  fill(
    bridge_baseline_date, bridge_v2_rand_date, bridge_v5_sched_final_visit_date
  ) |> 
  dplyr::ungroup()
```

We converted the variable indicating the type of session (`bridge_type`) into a factor.

```{r}
bridge_data <- bridge_data |>
    dplyr::mutate(
    # Change NA to None for type
    bridge_type = dplyr::if_else(is.na(bridge_type), 4, bridge_type),
    # Create factor version
    bridge_type_f = factor(
      bridge_type,
      1:4,
      c("case_management", "crisis_management", "other", "none")
    )
  )
```

#### Point-Modification of Dates

Certain dates were identified as having year typos or other issues within the original Bridge Data set. These entries received point-fixes, as agreed by PIs on 2023-11-22.

```{r}
bridge_fixes <- bridge_fixes |>
  rename_at('original_date', ~'bridge_date_session')

bridge_data <- left_join(bridge_data, bridge_fixes, by = c('subject', 'bridge_date_session')) |>
  mutate(bridge_date_session = if_else(
    !is.na(new_date), 
    new_date, 
    bridge_date_session
    )
  ) |>
  select(-new_date)
```

We purged the point-fix Data-frame, for memory management.

```{r}
rm(bridge_fixes)
```


### Processing

We merged the Visit Windows calculated from the Master Log data, to facilitate processing each row.
Using the Visit Windows, we were able to calculate the appropriate study visit to associate with each Bridge Session.

```{r}
bridge_data <- left_join(
  bridge_data, visit_windows, by = join_by (subject == id)
  ) |>
  dplyr::mutate(
    visit = dplyr::case_when(
               is.na(bridge_date_session) ~ 
                 NA,
               # If within a window, assign the value for that
               ((!is.na(bridge_date_session) & !is.na(end_window)) & 
                  (bridge_date_session %within% end_window)) ~
                 "6",
               ((!is.na(bridge_date_session) & !is.na(v5_window)) & 
                  (bridge_date_session %within% v5_window)) ~
                 "5",
               ((!is.na(bridge_date_session) & !is.na(v4_window)) & 
                  (bridge_date_session %within% v4_window)) ~
                 "4",
               ((!is.na(bridge_date_session) & !is.na(v3_window)) & 
                  (bridge_date_session %within% v3_window)) ~
                 "3",
               ((!is.na(bridge_date_session) & !is.na(v2_window)) & 
                  (bridge_date_session %within% v2_window)) ~
                 "2",
               TRUE ~ NA
              )
)
```

We then used the Session Type to initialize variables to count the number of each type of session, and the number of minutes spent in each session type.

```{r}
bridge_data <- bridge_data |>
  dplyr::mutate(
    # Create a dummy count for each session type
    reg_sessions = ifelse(
        bridge_type_f == 'case_management', 
        1,
        NA),
    crisis_sessions = ifelse(
        bridge_type_f == 'crisis_management', 
        1,
        NA),   
    other_sessions = ifelse(
        bridge_type_f == 'other', 
        1,
        NA)    
  ) |>
  dplyr::mutate(
    # Calculate the number of minutes in each type of session
    reg_minutes = ifelse(
        bridge_type_f == 'case_management', 
        bridge_duration,
        NA),
    crisis_minutes = ifelse(
        bridge_type_f == 'crisis_management', 
        bridge_duration,
        NA),   
    other_minutes = ifelse(
        bridge_type_f == 'other', 
        bridge_duration,
        NA)
    )
```

We then grouped our data by our Session-Visit composite key to aggregate the total number of sessions, minutes spent, and average minutes per session for each session type.

```{r}
bridge_data <- bridge_data |>
  group_by(subject, visit) |>
  dplyr::mutate(
    # Calculate the total number of each session type, and total minutes
    # per session type, for each combination of Subject and Visit
    reg_sessions = sum(reg_sessions, na.rm = TRUE),
    crisis_sessions = sum(crisis_sessions, na.rm = TRUE),
    other_sessions = sum(other_sessions, na.rm = TRUE),
    reg_minutes = sum(reg_minutes, na.rm = TRUE),
    crisis_minutes = sum(crisis_minutes, na.rm = TRUE),
    other_minutes = sum(other_minutes, na.rm = TRUE)
  ) |>
  dplyr::mutate(
    # Calculate the average duration of each session type for each
    # combination of Subject and Visit
    reg_avg_duration = dplyr::if_else(
      reg_sessions != 0, reg_minutes / reg_sessions, 0
      ),
    crisis_avg_duration = dplyr::if_else(
      crisis_sessions != 0, crisis_minutes / crisis_sessions, 0
      ),
    other_avg_duration = dplyr::if_else(
      other_sessions != 0, other_minutes / other_sessions, 0
      )
  ) |>
  dplyr::ungroup() |>
  # Reduce to subject, visit, and the session/minute/avg columns
  dplyr::select(
    subject, visit,
    reg_sessions, reg_minutes, reg_avg_duration, 
    crisis_sessions, crisis_minutes, crisis_avg_duration, 
    other_minutes, other_sessions, other_avg_duration
    ) |>
  # Extract only unique rows
  dplyr::distinct() |>
  # Select only records that were within a visit window
  dplyr::filter(!is.na(visit)) |>
    # Calculate the total number of sessions, minutes, and average duration
  dplyr::group_by(subject, visit) |>
  dplyr::mutate(
    total_sessions = sum(reg_sessions + crisis_sessions + other_sessions),
    total_minutes = sum(reg_minutes + crisis_minutes + other_minutes),
    total_avg_duration = if_else(
      total_sessions != 0, total_minutes/total_sessions, 0
      )
  ) |>
  dplyr::ungroup()
```

We then pivoted our data into our desired format, wherein a single row provided counts for each subject. We also calculated an aggregate total number of sessions, minutes spent, and average minutes per session that included all session types, for the V2-V5 range.

```{r}
bridge_data <- bridge_data |>
  # Omit any records after the V5 protocol date
  dplyr::filter(visit != '6') |>
  dplyr::mutate(visit = dplyr::case_when(
    visit == '2' ~ 'v1_v2',
    visit == '3' ~ 'v2_v3',
    visit == '4' ~ 'v3_v4',
    visit == '5' ~ 'v4_v5'
  )) |> 
  # Pivot into a single row per subject
  tidyr::pivot_wider(
    names_from = visit, 
    values_from = c(
      reg_sessions, reg_minutes, reg_avg_duration, 
      crisis_sessions, crisis_minutes, crisis_avg_duration, 
      other_minutes, other_sessions, other_avg_duration,
      total_sessions, total_minutes, total_avg_duration
      )
  ) |>
  # Fill any missing fields with 0
  dplyr::mutate_all(~replace_na(., 0)) |>
  # Calculate the V2-V5 counts
  dplyr::rowwise() |>
  dplyr::mutate(
    reg_sessions_v2_v5 = sum(
      reg_sessions_v2_v3, reg_sessions_v3_v4, reg_sessions_v4_v5
      ),
    reg_minutes_v2_v5 = sum(
      reg_minutes_v2_v3, reg_minutes_v3_v4, reg_minutes_v4_v5
      ),
    reg_avg_duration_v2_v5 = dplyr::if_else(
      reg_sessions_v2_v5 != 0, 
      reg_minutes_v2_v5 / reg_sessions_v2_v5,
      0
    ),
    crisis_sessions_v2_v5 = sum(
      crisis_sessions_v2_v3, crisis_sessions_v3_v4, crisis_sessions_v4_v5
      ),
    crisis_minutes_v2_v5 = sum(
      crisis_minutes_v2_v3, crisis_minutes_v3_v4, crisis_minutes_v4_v5
      ),
    crisis_avg_duration_v2_v5 = dplyr::if_else(
      crisis_sessions_v2_v5 != 0, 
      crisis_minutes_v2_v5 / crisis_sessions_v2_v5,
      0
    ),
    other_sessions_v2_v5 = sum(
      other_sessions_v2_v3, other_sessions_v3_v4, other_sessions_v4_v5
      ),
    other_minutes_v2_v5 = sum(
      other_minutes_v2_v3, other_minutes_v3_v4, other_minutes_v4_v5
      ),
    other_avg_duration_v2_v5 = dplyr::if_else(
      other_sessions_v2_v5 != 0, 
      other_minutes_v2_v5 / other_sessions_v2_v5,
      0
    ),
    total_sessions_v2_v5 = sum(
      total_sessions_v2_v3, total_sessions_v3_v4, total_sessions_v4_v5
      ),
    total_minutes_v2_v5 = sum(
      total_minutes_v2_v3, total_minutes_v3_v4, total_minutes_v4_v5
      ),
    total_avg_duration_v2_v5 = dplyr::if_else(
      total_sessions_v2_v5 != 0, 
      total_minutes_v2_v5 / total_sessions_v2_v5,
      0
    )
  ) |>
  # Organize columns
  dplyr::ungroup() |>
  dplyr::relocate(
    subject, 
    reg_sessions_v1_v2, reg_minutes_v1_v2, reg_avg_duration_v1_v2,
    reg_sessions_v2_v3, reg_minutes_v2_v3, reg_avg_duration_v2_v3,
    reg_sessions_v3_v4, reg_minutes_v3_v4, reg_avg_duration_v3_v4,
    reg_sessions_v4_v5, reg_minutes_v4_v5, reg_avg_duration_v4_v5,
    reg_sessions_v2_v5, reg_minutes_v2_v5, reg_avg_duration_v2_v5,
    crisis_sessions_v1_v2, crisis_minutes_v1_v2, crisis_avg_duration_v1_v2,
    crisis_sessions_v2_v3, crisis_minutes_v2_v3, crisis_avg_duration_v2_v3,
    crisis_sessions_v3_v4, crisis_minutes_v3_v4, crisis_avg_duration_v3_v4,
    crisis_sessions_v4_v5, crisis_minutes_v4_v5, crisis_avg_duration_v4_v5,
    crisis_sessions_v2_v5, crisis_minutes_v2_v5, crisis_avg_duration_v2_v5,
    other_sessions_v1_v2, other_minutes_v1_v2, other_avg_duration_v1_v2,
    other_sessions_v2_v3, other_minutes_v2_v3, other_avg_duration_v2_v3,
    other_sessions_v3_v4, other_minutes_v3_v4, other_avg_duration_v3_v4,
    other_sessions_v4_v5, other_minutes_v4_v5, other_avg_duration_v4_v5,
    other_sessions_v2_v5, other_minutes_v2_v5, other_avg_duration_v2_v5,
    total_sessions_v1_v2, total_minutes_v1_v2, total_avg_duration_v1_v2,
    total_sessions_v2_v3, total_minutes_v2_v3, total_avg_duration_v2_v3,
    total_sessions_v3_v4, total_minutes_v3_v4, total_avg_duration_v3_v4,
    total_sessions_v4_v5, total_minutes_v4_v5, total_avg_duration_v4_v5,
    total_sessions_v2_v5, total_minutes_v2_v5, total_avg_duration_v2_v5
  )
```

We gave labels to each of the variables in this processed data set.

```{r}
attributes(bridge_data$subject)$label <- "Subject ID Number (eligible)"

# Regular Sessions
attributes(bridge_data$reg_sessions_v1_v2)$label <- paste0(
  "Number of regular case management sessions, V1-V2"
  )
attributes(bridge_data$reg_sessions_v2_v3)$label <- paste0(
  "Number of regular case management sessions, V2-V3"
  )
attributes(bridge_data$reg_sessions_v3_v4)$label <- paste0(
  "Number of regular case management sessions, V3-V4"
  )
attributes(bridge_data$reg_sessions_v4_v5)$label <- paste0(
  "Number of regular case management sessions, V4-V5"
  )
attributes(bridge_data$reg_sessions_v2_v5)$label <- paste0(
  "Number of regular case management sessions, V2-V5"
  )
# Regular Minutes
attributes(bridge_data$reg_minutes_v1_v2)$label <- paste0(
  "Number of minutes spent in regular case management sessions, ",
  "V1-V2"
  )
attributes(bridge_data$reg_minutes_v2_v3)$label <- paste0(
  "Number of minutes spent in regular case management sessions, ",
  "V2-V3"
  )
attributes(bridge_data$reg_minutes_v3_v4)$label <- paste0(
  "Number of minutes spent in regular case management sessions, ",
  "V3-V4"
  )
attributes(bridge_data$reg_minutes_v4_v5)$label <- paste0(
  "Number of minutes spent in regular case management sessions, ",
  "V4-V5"
  )
attributes(bridge_data$reg_minutes_v2_v5)$label <- paste0(
  "Number of minutes spent in regular case management sessions, ",
  "V2-V5"
  )
# Regular Average Duration
attributes(bridge_data$reg_avg_duration_v1_v2)$label <- paste0(
  "Average number of minutes per session for regular case management ", 
  "sessions, V1-V2"
  )
attributes(bridge_data$reg_avg_duration_v2_v3)$label <- paste0(
  "Average number of minutes per session for regular case management ", 
  "sessions, V2-V3"
  )
attributes(bridge_data$reg_avg_duration_v3_v4)$label <- paste0(
  "Average number of minutes per session for regular case management ", 
  "sessions, V3-V4"
  )
attributes(bridge_data$reg_avg_duration_v4_v5)$label <- paste0(
  "Average number of minutes per session for regular case management ", 
  "sessions, V4-V5"
  )
attributes(bridge_data$reg_avg_duration_v2_v5)$label <- paste0(
  "Average number of minutes per session for regular case management ", 
  "sessions, V2-V5"
  )
# Crisis Sessions
attributes(bridge_data$crisis_sessions_v1_v2)$label <- paste0(
  "Number of Crisis case management sessions, V1-V2"
  )
attributes(bridge_data$crisis_sessions_v2_v3)$label <- paste0(
  "Number of Crisis case management sessions, V2-V3"
  )
attributes(bridge_data$crisis_sessions_v3_v4)$label <- paste0(
  "Number of Crisis case management sessions, V3-V4"
  )
attributes(bridge_data$crisis_sessions_v4_v5)$label <- paste0(
  "Number of Crisis case management sessions, V4-V5"
  )
attributes(bridge_data$crisis_sessions_v2_v5)$label <- paste0(
  "Number of Crisis case management sessions, V2-V5"
  )
# Crisis Minutes
attributes(bridge_data$crisis_minutes_v1_v2)$label <- paste0(
  "Number of minutes spent in Crisis case management sessions, ",
  "V1-V2"
  )
attributes(bridge_data$crisis_minutes_v2_v3)$label <- paste0(
  "Number of minutes spent in Crisis case management sessions, ",
  "V2-V3"
  )
attributes(bridge_data$crisis_minutes_v3_v4)$label <- paste0(
  "Number of minutes spent in Crisis case management sessions, ",
  "V3-V4"
  )
attributes(bridge_data$crisis_minutes_v4_v5)$label <- paste0(
  "Number of minutes spent in Crisis case management sessions, ",
  "V4-V5"
  )
attributes(bridge_data$crisis_minutes_v2_v5)$label <- paste0(
  "Number of minutes spent in Crisis case management sessions, ",
  "V2-V5"
  )
# Crisis Average Duration
attributes(bridge_data$crisis_avg_duration_v1_v2)$label <- paste0(
  "Average number of minutes per session for Crisis case management ", 
  "sessions, V1-V2"
  )
attributes(bridge_data$crisis_avg_duration_v2_v3)$label <- paste0(
  "Average number of minutes per session for Crisis case management ", 
  "sessions, V2-V3"
  )
attributes(bridge_data$crisis_avg_duration_v3_v4)$label <- paste0(
  "Average number of minutes per session for Crisis case management ", 
  "sessions, V3-V4"
  )
attributes(bridge_data$crisis_avg_duration_v4_v5)$label <- paste0(
  "Average number of minutes per session for Crisis case management ", 
  "sessions, V4-V5"
  )
attributes(bridge_data$crisis_avg_duration_v2_v5)$label <- paste0(
  "Average number of minutes per session for Crisis case management ", 
  "sessions, V2-V5"
  )
# Other Sessions
attributes(bridge_data$other_sessions_v1_v2)$label <- paste0(
  "Number of Other case management sessions, V1-V2"
  )
attributes(bridge_data$other_sessions_v2_v3)$label <- paste0(
  "Number of Other case management sessions, V2-V3"
  )
attributes(bridge_data$other_sessions_v3_v4)$label <- paste0(
  "Number of Other case management sessions, V3-V4"
  )
attributes(bridge_data$other_sessions_v4_v5)$label <- paste0(
  "Number of Other case management sessions, V4-V5"
  )
attributes(bridge_data$other_sessions_v2_v5)$label <- paste0(
  "Number of Other case management sessions, V2-V5"
  )
# Other Minutes
attributes(bridge_data$other_minutes_v1_v2)$label <- paste0(
  "Number of minutes spent in Other case management sessions, ",
  "V1-V2"
  )
attributes(bridge_data$other_minutes_v2_v3)$label <- paste0(
  "Number of minutes spent in Other case management sessions, ",
  "V2-V3"
  )
attributes(bridge_data$other_minutes_v3_v4)$label <- paste0(
  "Number of minutes spent in Other case management sessions, ",
  "V3-V4"
  )
attributes(bridge_data$other_minutes_v4_v5)$label <- paste0(
  "Number of minutes spent in Other case management sessions, ",
  "V4-V5"
  )
attributes(bridge_data$other_minutes_v2_v5)$label <- paste0(
  "Number of minutes spent in Other case management sessions, ",
  "V2-V5"
  )
# Other Average Duration
attributes(bridge_data$other_avg_duration_v1_v2)$label <- paste0(
  "Average number of minutes per session for Other case management ", 
  "sessions, V1-V2"
  )
attributes(bridge_data$other_avg_duration_v2_v3)$label <- paste0(
  "Average number of minutes per session for Other case management ", 
  "sessions, V2-V3"
  )
attributes(bridge_data$other_avg_duration_v3_v4)$label <- paste0(
  "Average number of minutes per session for Other case management ", 
  "sessions, V3-V4"
  )
attributes(bridge_data$other_avg_duration_v4_v5)$label <- paste0(
  "Average number of minutes per session for Other case management ", 
  "sessions, V4-V5"
  )
attributes(bridge_data$other_avg_duration_v2_v5)$label <- paste0(
  "Average number of minutes per session for Other case management ", 
  "sessions, V2-V5"
  )
# Total Sessions
attributes(bridge_data$total_sessions_v1_v2)$label <- paste0(
  "Number of case management sessions, any type, V1-V2"
  )
attributes(bridge_data$total_sessions_v2_v3)$label <- paste0(
  "Number of case management sessions, any type V2-V3"
  )
attributes(bridge_data$total_sessions_v3_v4)$label <- paste0(
  "Number of case management sessions, any type, V3-V4"
  )
attributes(bridge_data$total_sessions_v4_v5)$label <- paste0(
  "Number of case management sessions, any type, V4-V5"
  )
attributes(bridge_data$total_sessions_v2_v5)$label <- paste0(
  "Number of case management sessions, any type, V2-V5"
  )
# Total Minutes
attributes(bridge_data$total_minutes_v1_v2)$label <- paste0(
  "Number of minutes spent in case management sessions, any type, ",
  "V1-V2"
  )
attributes(bridge_data$total_minutes_v2_v3)$label <- paste0(
  "Number of minutes spent in case management sessions, any type, ",
  "V2-V3"
  )
attributes(bridge_data$total_minutes_v3_v4)$label <- paste0(
  "Number of minutes spent in case management sessions, any type, ",
  "V3-V4"
  )
attributes(bridge_data$total_minutes_v4_v5)$label <- paste0(
  "Number of minutes spent in case management sessions, any type, ",
  "V4-V5"
  )
attributes(bridge_data$total_minutes_v2_v5)$label <- paste0(
  "Number of minutes spent in case management sessions, any type, ",
  "V2-V5"
  )
# Total Average Duration
attributes(bridge_data$total_avg_duration_v1_v2)$label <- paste0(
  "Average number of minutes per session for case management, any type ", 
  "sessions, V1-V2"
  )
attributes(bridge_data$total_avg_duration_v2_v3)$label <- paste0(
  "Average number of minutes per session for case management, any type ", 
  "sessions, V2-V3"
  )
attributes(bridge_data$total_avg_duration_v3_v4)$label <- paste0(
  "Average number of minutes per session for case management, any type ", 
  "sessions, V3-V4"
  )
attributes(bridge_data$total_avg_duration_v4_v5)$label <- paste0(
  "Average number of minutes per session for case management, any type ", 
  "sessions, V4-V5"
  )
attributes(bridge_data$total_avg_duration_v2_v5)$label <- paste0(
  "Average number of minutes per session for case management, any type ", 
  "sessions, V2-V5"
  )
```

### üíæ Save the Processed Bridge Session Data

We set our desired output paths for the processed data

```{r}
# RDS version
rds_path <- here(
  "data", "bridge_session_data", "bridge_1.rds"
  )

# MB also wants an SPSS version
spss_path <- here(
  "data", "bridge_session_data", "bridge_1.sav"
  )
```

We performed a check for any changes to the processed data since it was last saved in RDS format.

```{r}
# Inputs last modified: 2023-12-11

data_mod_check(
  'df' = bridge_data,
  'df_path_str' = rds_path,
  'orig_path_str' = here(
      "data", "bridge_session_data", "bridge_1.rds"
      ),
  'mod_dt' = NA,
  'num_rows' = 334,
  'num_cols' = 61,
  'col_names' = bridge_proc_cols
  )
# TRUE
```

And we performed a check for any changes to the processed data since it was last saved in SPSS format.

```{r}
# Inputs last modified: 2023-12-11

data_mod_check(
  'df' = bridge_data,
  'df_path_str' = spss_path,
  'orig_path_str' = here(
      "data", "bridge_session_data", "bridge_1.sav"
      ),
  'mod_dt' = NA,
  'num_rows' = 334,
  'num_cols' = 61,
  'col_names' = bridge_proc_cols
  )
# TRUE
```

We exported our files.

```{r}
# Processed Bridge data RDS
readr::write_rds(bridge_data, rds_path)

# Processed Bridge data SPSS
haven::write_sav(bridge_data, spss_path)

```

Print a message for when this file is saved.

```{r}
cat(
  paste0(Sys.Date(), ":"),
  "Processed Bridge Session saved to", rds_path, "and", spss_path
)
```

Purge path variables and exported data to avoid potential errors in later processing.

```{r}
rm(rds_path)
rm(spss_path)
rm(bridge_data)
rm(bridge_proc_cols)
```

# Clean Up

The remaining global variables were purged for memory management.

```{r}
rm(avail_col_list)
rm(visit_windows)
```
