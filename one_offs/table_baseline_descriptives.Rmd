---
title: "Big Descriptives Table"
date: "2020-12-21"
---

# ⭐️Overview

**2020-12-10**

Hi Brad. My staff are writing 3 papers from the Link2Care baseline/randomization visit data set.

We did some preliminary analyses and all look like they are legit papers...

I am writing to ask if you are willing to do the official analyses for these papers (the analyses are pretty basic, with one having some mediation analyses [using the Preacher and Hayes SPSS macro add on]). Of course, you would be an author on all 3.

Let me know if this works for you.

**2020-12-11**

Excellent! I will put you in touch with the staff members and walk you through the analyses.

Can you start by recreating a baseline table with all the variables below (use all participants to date that have completed the baseline and randomization visits). Just 1 long table. The staff members will take what they need for their papers. The items below are pretty much all of the variables being used across all 3 papers. There may be an additional variable or two to add later.

1. Sex ✅
2. Race ✅
3. Ethnicity ✅ 
4. Age ✅
5. marital status ✅
6. employment status ✅
7. years of education ✅
8. veteran (% yes) ✅
9. sexual orientation ✅
10. number of children ✅
11. homelessness (current period Median; and lifetime Median)✅
  - homeless_time_total ✅
  - homeless_current_total ✅
12. reasons for current homelessness (distribution) ✅
13. total times homeless ✅
14. age at first homelessness ✅
15. mini mental status exam total score (M; SD) ✅
  - 2020-12-24, from Joe Waring: "Please use MMS_total. This variable corrects for the missing data/data showing -1 in MMS_S. QDS outputs a -1 when participants are able to count backward from 100 by 7’s and skip the spell WORLD backward question."
16. Arrest history (number of arrests; total period in jail Median✅) 
17. Type of health insurance (distribution) ✅
18. Do you have an active cell phone (% yes) ✅
19. Who pays for your cell phone service (distribution) ✅
20. How many 'talk' minutes does your plan have (distribution) ✅
21. Is your cell phone a smart phone? (distribution) ✅
22. Does your phone service include a data plan (distribution) ✅
23. How many times has your phone number changed in the past year (distribution) ✅
24. Which of the following forms of media do you use (distribution) ✅
25. How often do you access the internet (distribution) ✅
26. Do you have an active Facebook page (% yes) ✅
27. How often do you check or post on Facebook (distribution) ✅
28. Do you believe that a smartphone app can help you to change your actions or behaviors (% yes) ✅
30. Have you ever used a smartphone app to manage one or more health-related issues (% yes) ✅
31. What type of health related issue (distribution) ✅
32. PHQ-8 score ✅
33. % with PHQ-8 \>10 ✅
34. Aggression Questionnaire mean (SD) ✅
35. CJ Client Evaluation of Self and Treatment (TCU CJ CEST) -- mean (SD) ✅
36. Urban Life Stress Scale -- Mean (SD) ✅
37. Personal victimization (distribution of each of 3 items) ✅
38. Detroit Area Assessment of Day-to-Day Discrimination Mean (SD) of scale -- 1st 9 items (Item 10 is separate = cause of discrimination -- please include distribution of item 10) ✅
39. MacArthur Major Discrimination -- total score Personal victimization (distribution of each of 3 items) ✅
40. % currently receiving treatment for mental health problems ✅
41. Total drinks per week from Alcohol Quantity and Frequency questionnaire ✅
42. Number binge drinking days in past 30 days ✅
43. Perceived stress scale total score (M; SD) ✅
44. Distress Tolerance Scale (total score; M, SD) ✅
45. GAD-7 total score ✅
46. CESD total score ✅
47. ISEL social support – total score and each of 3 subscales ✅
48. Panas positive affect 🚫
49. Panas negative affect 🚫
50. Meals survey item 4 (\# meals missed in past week; M; SD) ✅
51. SF-12 total score ✅
  - pcs_12_v1✅
  - mcs_12_v1✅
52. HrQol -- each of the 4 items separately (\# days with mental health problems, \# days with physical health problems, \# days MH or PH problems limit activities, how would you rate your health in general) ✅
  - hrq_physical_30 ✅
  - hrq_mental_30 ✅
  - hrq_mental_30 ✅
  - gen_health_f ✅

Thanks Brad. We hope to get these all under review in January!

# 📦Load packages

```{r message=FALSE}
library(dplyr)
library(haven)
library(readr)
library(readxl)
library(stringr)
library(tidyr)
library(meantables)
library(freqtables)
library(purrr)
library(flextable)
library(officer)
```

# 🌎Connect to UTH server 

```{bash}
# Don't drill all the way down to live documents because not all of the data is in live documents.
open 'smb://islgpcifs.uthouston.edu/sph_research/Link2Care/'
```

# 📥Import data 

Below, we run the file, data_survey_01_import.Rmd, which is used to import the Link2Care follow-up visit survey data and do some initial data cleaning (e.g., create calculated variables).

```{r message=FALSE}
source_rmd <- function(file, ...) {
  tmp_file = tempfile(fileext=".R")
  on.exit(unlink(tmp_file), add = TRUE)
  knitr::purl(file, output=tmp_file)
  source(file = tmp_file, ...)
}

source_rmd("data_survey_01_import.Rmd")

rm(source_rmd)
# 263 rows and 2855 columns
```

Import list of analysis variables. Normally, I wouldn't do it this way, but there are just so many variables that it's easier to keep track of them all and keep them in order using a spreadsheet.

```{r}
analysis_vars    <- read_excel("codebooks/descriptive_table_analysis_vars.xlsx")
continuous_vars  <- analysis_vars %>% filter(cat == 0) %>% pull(var)
categorical_vars <- analysis_vars %>% filter(cat == 1) %>% pull(var)
```


# 🚧Data management 

Only do data management in this file that applies to this analysis only. If the data management task is likely to be more broadly applicable, then add it to data_survey_01_import.Rmd.

## Keep columns of interest

This is strictly necessary, but it makes the data easier to work with.

```{r}
baseline <- all_visits %>% 
  select(
    id, group, all_of(pull(analysis_vars, var))
  )
```

```{r}
dim(baseline) # 263  75
```

## Reshape wide to long

**NOTE on reshaping:** Not currently reshaping anymore. The way I've kept variables (e.g., var_v1 or var_v2) means that I have a wide data from with each persons "baseline" value (i.e., at v1 or v2 for questions that weren't asked at v1 -- Michael asked for it to be this way). Therefore, there is no need to create a long data frame. I do want to save this code for the future though.

The visit variable is currently in wide form. Make longer so that each row represents a unique person/visit combination.

2020-12-14, from Joe: Missing date in TODAY_V. Sometimes QDS did not capture the date for some odd reason. If there is data in VISIT_V or GROUP then the visit occurred. If they are missing data in both of those variables then the visit likely didn’t occur or it happened in REDCap. Below are the records and visits that occurred in REDCap.

2235       Visit 4
2237       Visit 4
2238       Visit 4
2247       Visit 4
2248       Visit 4
2249       Visit 3
2252       Visit 3


NOTE: "If there is data in VISIT_V or GROUP then the visit occurred." can't be right because they are assigned group at visit two. So, they could easily have no date and have been assigned to a group, but not yet attended visit 3. Visit 3 should be 0, not 1. So, we can only use group assignment as a criteria for visits 1 and 2. In other words, if they have no date for visit 2 and no "visit_v" identifier for visit 2, but they have group identifier, then we will say they attended visit 2.

```{r}
# all_visits_long <- all_visits %>% 
#   # For testing
#   # select(id, group, starts_with("TODAY"), starts_with("VISIT")) %>%
#   pivot_longer(
#     cols = c(starts_with("TODAY"), starts_with("VISIT")),
#     names_to = c(".value", "value"),
#     names_pattern = "([A-Z]+)_V([1-5])"
#   ) %>% 
#   # Rename columns
#   rename(
#     visit = value,
#     date = TODAY,
#     attend_visit = VISIT
#   ) %>% 
#   # Create a calculated version of attend visit using the criteria Joe sent
#   # (See above)
#   mutate(attend_visit_c = case_when(
#     # If there is a date then they attended. I checked and there aren't any
#     # cases where there is a date and attend_visit is zero, but I'm putting
#     # this rule in anyway.
#     !is.na(date) ~ 1L,
#     # If there is data in VISIT_V or GROUP then the visit occurred (see above).
#     attend_visit == 1 ~ 1L,
#     !is.na(group) & visit <= 2 ~ 1L,
#     # Add the Redcap cases.
#     id == 2235 & visit == 4 ~ 1L,
#     id == 2237 & visit == 4 ~ 1L,
#     id == 2238 & visit == 4 ~ 1L,
#     id == 2247 & visit == 4 ~ 1L,
#     id == 2248 & visit == 4 ~ 1L,
#     id == 2249 & visit == 3 ~ 1L,
#     id == 2252 & visit == 3 ~ 1L,
#     # Otherwise, they didn't attend (yet).
#     TRUE ~ 0L
#   )) %>% 
#   # Reorder columns
#   select(-attend_visit) %>% 
#   select(id, group, date, visit, attend_visit_c, everything())
#   
#   # For data checking
#   # filter(is.na(date) & attend_visit == 1)
#   # filter(attend_visit != attend_visit_c)
```

```{r}
# dim(all_visits_long) # 1305 2365
```


## Filter out rows in the table

2020-12-08, from Michael: Can you start by recreating a baseline table with all the variables below (use all participants to date that have completed the baseline and randomization visits)?

2021-01-20: Michael said to consider visit 2 answers to be "baseline" answers for questions that weren't asked at visit 1.

Select people who were randomized only

```{r}
baseline_randomized <- baseline %>% 
  filter(group %in% 1:3)
```

```{r}
dim(baseline_randomized) # 244  75
```

## Export analysis data

2021-01-29: Michael asked me to export the analysis data and upload it to Kiteworks.

```{r}
write_sav(baseline_randomized, "/Users/bradcannell/Desktop/baseline_randomized.sav")
```


# 📈Analysis

## 🟠Continuous variables

For now, we'll get the mean with confidence interval and median with confidence interval.

Useful website:
<https://stats.stackexchange.com/questions/21103/confidence-interval-for-median>

### Helper function for median and CI

```{r}
median_ci <- function(.data, .x) {
  .data %>% 
    summarise(
      var = !!quo_name(enquo(.x)),
      n   = sum(!is.na({{.x}})),
      n_miss = sum(is.na({{.x}})),
      median = median({{.x}}, na.rm = TRUE),
      lcl = sort({{.x}})[qbinom(.025, length({{.x}}), 0.5)],
      ucl = sort({{.x}})[qbinom(.975, length({{.x}}), 0.5)]
    )
}

# # For testing
# visit_1_randomized %>% 
#   median_ci(age)
```

### Helper function for joing mean stats and median stats

```{r}
mean_median_ci <- function(.data, .x, .digits) {
  mean_stats <- .data %>% 
    mean_table({{.x}}) %>% 
    freq_format("mean (lcl - ucl)", digits = .digits) %>% 
    select(var = response_var, n, mean_ci = formatted_stats) 
    
  median_stats <- .data %>%
    median_ci({{.x}}) %>% 
    freq_format("median (lcl - ucl)", digits = 1) %>% 
    select(var, median_ci = formatted_stats)
  
  # Join them together
  out <- left_join(mean_stats, median_stats, by = "var")
  out
}

# # For testing
# visit_1_randomized %>% 
#   mean_median_ci(age, 1)
```

### Loop over all continuous vars

```{r}
cont_stats <- map_df(
  syms(continuous_vars), 
  function(x) {
    baseline_randomized %>%
      mean_median_ci({{x}}, 1)
  }
)
```

### Change row headers

```{r}
cont_stats <- cont_stats %>% 
  mutate(var = case_when(
    var == "age" ~ "Age (years)",
    var == "mms_total" ~ "MMSE Total Score",
    var == "homeless_time_total" ~ "Lifetime total time homeless (months)",
    var == "homeless_current_total" ~ "Current total time homeless (months)",
    var == "homeless_age_first_time" ~ "Age when first became homeless (years)",
    var == "jail_time_total_c" ~ "Lifetime total time in jail or prison (years)",
    var == "phq_8_total" ~ "PHQ-8 score",
    var == "gad_7_total_v1" ~ "GAD-7 total score",
    var == "pcs_12_v1" ~ "SF-12 Physical Component Summary score",
    var == "mcs_12_v1" ~ "SF-12 Mental Component Summary score",
    var == "hrq_physical_30" ~ "N days out of past 30 physical health not good",
    var == "hrq_mental_30" ~ "N days out of past 30 mental health not good",
    var == "hrq_limit_activities_30" ~ "N days out of past 30 poor health prevent activities",
    var == "drink_avg_per_week_v1" ~ "Total drinks on average week",
    var == "binge_drink_days_v1" ~ "N Binge drinking days in past 30 days",
    var == "dd_v1_total" ~ "Detroit Day Discrimination summary score",
    var == "agression_total" ~ "Aggression questionnaire total",
    var == "ces_v1_total" ~ "CES-D total score",
    var == "ise_appraisal_v1" ~ "ISE appraisal score",
    var == "ise_belonging_v1" ~ "ISE belonging score",
    var == "ise_tangable_v1" ~ "ISE tangable score",
    var == "tcu_treatment_sat_v2" ~ "TCU treatment satisfaction subscale",
    var == "macarthur_total" ~ "MacArthur Major Discrimination total score",
    var == "uls_v2_total" ~ "Urban Life Stress Scale total score",
    var == "ps_v2_total" ~ "Perceived Stress Scale total score",
    var == "dts_total_v2" ~ "Distress Tolerance Scale total score",
    TRUE ~ var
  ))
```

### Make flextable

```{r}
cont_stats_ft <- cont_stats %>% 
  flextable()
```

### Format flextable

```{r}
cont_stats_ft <- cont_stats_ft %>% 
  # Change column headers
  set_header_labels(
    var = "Variable",
    n = "n",
    mean_ci = "Mean (95% CI)",
    median_ci = "Median (95% CI)"
  ) %>% 
  # Change column widths
  width(width = 1.63) %>% 
  # Add title to top of table
  # Add a blank title line to top of table first
  add_header_lines("") %>% 
  # Use compose to bold "Table #."
  flextable::compose(
    i = 1, part = "header",
    value = as_paragraph(
      as_chunk(
        "Table 1. ", props = fp_text(
          font.size = 11, bold = TRUE, font.family = "Times New Roman"
        )
      ),
      "Descriptive statistics for continuous variables at baseline."
    ),
  ) %>% 
  # Left align title
  align(align = "left", part = "header") %>%
  # Left align first column
  align(j = 1, align = "left", part = "body") %>%
  # Center align remaining columns
  align(j = 2:4, align = "center", part = "all") %>%
  # Change font to TNR 11
  font(fontname = "Times New Roman", part = "all")
```

## 🔵Categorical variables

2020-12-24, from Michael: Use BH15V1 for number of times arrested.

### Loop over all categorical vars

```{r}
cat_stats <- map_df(
  syms(categorical_vars), 
  function(x) {
    baseline_randomized %>%
      filter(!is.na({{x}})) %>% 
      freq_table({{x}}) %>%
      freq_format(recipe = "n (percent)", digits = 1) %>%
      select(var, cat, formatted_stats) %>%
      # Add a row with the var name only
      add_row(var = quo_name(x), .before = 1) %>% 
      # Add blank row below
      add_row(var = "", cat = "", formatted_stats = "")
  }
) %>% 
  # Drop the final empty row
  slice(-n())
```

### Change row headers

```{r}
cat_stats <- cat_stats %>%
  mutate(var = case_when(
    var == "gender_v1_f" ~ "Gender",
    var == "hispanic_f" ~ "Hispanic ethnicity",
    var == "race_f" ~ "Race",
    var == "cell_have_f" ~ "Have cell phone",
    var == "cell_pays_f" ~ "Who pays for cell phone",
    var == "cell_talk_minutes_f" ~ "Talk minutes on cell plan",
    var == "cell_smart_f" ~ "Is your cell phone a smart phone?",
    var == "cell_data_plan_f" ~ "Does your phone service include a data plan?",
    var == "cell_number_change_f" ~ "How many times has your phone number changed in the past year?",
    var == "media_use_email_f" ~ "Use email",
    var == "media_use_facebook_f" ~ "Use Facebook",
    var == "media_use_google_plus_f" ~ "Use Google Plus",
    var == "media_use_twitter_f" ~ "Use Twitter",
    var == "media_use_blogs_f" ~ "Use Blogs",
    var == "media_use_instagram_f" ~ "Use Instagram",
    var == "media_use_snapchat_f" ~ "Use Snapchat",
    var == "media_use_linkedin_f" ~ "Use LinkedIn",
    var == "media_use_none_f" ~ "Don't use any media",
    var == "access_internet_f" ~ "How often do you access the internet?",
    var == "facebook_active_f" ~ "Do you have an active Facebook page?",
    var == "facebook_check_f" ~ "How often do you check or post on Facebook?",
    var == "marital_5_cat_f" ~ "Marital status",
    var == "n_child_f" ~ "Number of children",
    var == "edu_19_cat_f" ~ "Completed formal education",
    var == "ged_f" ~ "Have GED or HS diploma",
    var == "employ_9_cat_f" ~ "Employment status",
    var == "ins_6_cat_f" ~ "Insurance",
    var == "veteran_f" ~ "Veteran status",
    var == "sexual_orientation_f" ~ "Sexual orientation",
    var == "transgender_f" ~ "Transgender",
    var == "homeless_periods_f" ~ "Lifetime separate periods of homelessness",
    var == "homeless_mental_treatment_f" ~ "Currently receiving treatment for mental health problems",
    var == "homeless_reason_13_cat_f" ~ "Reason for current homelessness",
    var == "jail_lifetime_n_f" ~ "Lifetime separate times to jail or prison",
    var == "phq_8_gt_10_f" ~ "PHQ-8 score greater than 10",
    var == "gen_health_v1_f" ~ "General health",
    var == "sp_app_change_behavior_f" ~ "Smartphone app can help you to change your actions or behavior",
    var == "sp_app_manage_health_f" ~ "Ever used smartphone app to manage one or more health-related issues",
    var == "sp_app_health_type_f" ~ "Type of health related issue managed with smartphone apps",
    var == "meals_missed_week_f" ~ "Meals missed past week because unable to find food",
    var == "ddd_main_reason_f" ~ "DDD: Main reason for discrimination experienced",
    var == "macarthur_main_reason_f" ~ "MacArthur: Main reason for discrimination experienced",
    var == "macarthur_interfere_f" ~ "MacArthur: Overall discrimination interfered with full and productive life",
    var == "macarthur_harder_life_f" ~ "MacArthur: Overall how much harder life is because of discrimination",
    var == "pv_violence_victim_30_f" ~ "Times experienced violence past 30 days ",
    var == "pv_witness_violence_30_f" ~ "Times witnessed to acts of violence past 30 days",
    var == "pv_witness_violence_6_f" ~ "Times witnessed to acts of violence past 6 months",
    TRUE ~ var
  ))
```

### Slide categories over

```{r}
cat_stats <- cat_stats %>%
  mutate(
    # Slide categories over
    var = if_else(is.na(cat), var, cat)
  ) %>%
  select(-cat)
```

### Make flextable

```{r}
cat_stats_ft <- cat_stats %>% 
  flextable()
```

### Format flextable

```{r}
# Use for bolding below
header_fmt <- fp_text(font.size = 11, bold = TRUE, font.family = "Times New Roman")

cat_stats_ft <- cat_stats_ft %>% 
  # Change column headers
  set_header_labels(
    var = "Variable",
    formatted_stats = "n (percent)"
  ) %>% 
  # Change column widths
  width(width = c(4.88, 1.63)) %>% 
  # Add title to top of table
  # Add a blank title line to top of table first
  add_header_lines("") %>% 
  # Use compose to bold "Table #."
  flextable::compose(
    i = 1, part = "header",
    value = as_paragraph(
      as_chunk(
        "Table 2. ", props = fp_text(
          font.size = 11, bold = TRUE, font.family = "Times New Roman"
        )
      ),
      "Descriptive statistics for categorical variables at baseline."
    ),
  ) %>% 
  # Left align title
  align(align = "left", part = "header") %>%
  # Left align first column
  align(j = 1, align = "left", part = "body") %>%
  # Center align remaining columns
  align(j = 2, align = "center", part = "all") %>%
  # Change font to TNR 11
  font(fontname = "Times New Roman", part = "all")
```

# 📄Add tables to Word document

```{r}
descriptive_stats <- read_docx("table_big_descriptive_template.docx") %>%
  # Add the total n
  body_replace_text_at_bkm(
    bookmark = "n_randomized",
    value = paste0(" ", nrow(baseline_randomized))
  ) %>% 
  # Add date updated
  body_replace_text_at_bkm(
    bookmark = "date",
    value = format(Sys.Date(), "%B %d, %Y")
  )
```

Add table of continuous stats

```{r}
descriptive_stats <- descriptive_stats %>%
  body_replace_flextable_at_bkm(
    bookmark = "table_1",
    value = cont_stats_ft
  )
```

Add table of categorical stats

```{r}
descriptive_stats <- descriptive_stats %>%
  body_replace_flextable_at_bkm(
    bookmark = "table_2",
    value = cat_stats_ft
  )
```

```{r}
print(
  descriptive_stats, 
  "L2C Baseline Descriptive Tables.docx"
)
```



