---
title: "Link2Care Survey Data - Merge Survey Data"
date: "2021-04-28 <br> Updated: `r Sys.Date()`"
---

# ‚≠êÔ∏èOverview

We previously imported and did some initial cleaning of the following data sets:

* QDS (data_survey_01_qds_import.Rmd) 
* Redcap (data_survey_02_redcap_import.Rmd) 
* Master log (data_survey_03_master_log_import.Rmd)   
* Timeline followback (data_survey_04_tlfb_import.Rmd)   
* Arrest data (data_survey_05_arrests_import.Rmd)   
* Bridge sessions data (data_survey_06_bridge_sessions_import.Rmd)
* DDT data (data_survey_07_ddt_import.Rmd)   

This file is used to merged together all of those individual data sets into a single survey data analysis data set.


# üì¶Load packages

```{r message=FALSE}
library(dplyr, warn.conflicts = FALSE)
library(readr, warn.conflicts = FALSE)
library(purrr, warn.conflicts = FALSE)
library(testthat, warn.conflicts = FALSE) # Delete after you remove all testthat chunks
library(stringr, warn.conflicts = FALSE)
library(tidyr, warn.conflicts = FALSE)
library(haven, warn.conflicts = FALSE)
library(lubridate, warn.conflicts = FALSE)
library(data.table, warn.conflicts = FALSE)
```

```{r}
source("R/fact_reloc.R")
```



# üì•Import data 

We previously imported and did some initial cleaning of the following data sets:

* QDS (data_survey_01_qds_import.Rmd)
* Redcap (data_survey_02_redcap_import.Rmd)    
* Master log (data_survey_03_master_log_import.Rmd)   
* Timeline followback (data_survey_04_tlfb_import.Rmd)   
* Arrest data (data_survey_05_arrests_import.Rmd)   
* Bridge sessions data (data_survey_06_bridge_sessions_import.Rmd)
* DDT data (data_survey_07_ddt_import.Rmd)   

Most of the data cleaning that was done was to standardize column names. [Click here](https://github.com/brad-cannell/link2care_public/blob/master/data/notes_cleaning_individual_data_sets_for_merge.md) for notes on column naming conventions. 

After doing this initial cleaning, the individual files were saved in RDS format on Teams.

```{r}
data_frames <- c(
  qds    = "data/qds/qds_all_visits_import.rds",
  rc     = "data/redcap/redcap_import.rds",
  ml     = "data/master_log/master_log_screened_in.rds",
  tlfb   = "data/tlfb/tlfb.rds",
  arrest = "data/arrest/arrest.rds",
  bridge = "data/bridge_session_data/bridge_wide.rds",
  ddt    = "data/ddt/ddt.rds"
)
```

```{r}
for (i in seq_along(data_frames)) {
  path  <- data_frames[[i]]
  df_nm <- names(data_frames)[[i]]
  df    <- read_rds(path)
  assign(df_nm, df, envir = .GlobalEnv)
  
  # Print a message for when this file is being sourced
  cat(
    paste0(Sys.Date(), ":"),
    data_frames[[i]], "imported as", df_nm, "with", nrow(df), "rows and", 
    ncol(df), "columns.\n"
  )
}

rm(df_nm, i, path)

# 2023-08-25: data/qds/qds_all_visits_import.rds imported as qds with 1506 rows and 1048 columns.
# 2023-08-25: data/redcap/redcap_import.rds imported as rc with 108 rows and 659 columns.
# 2023-08-25: data/master_log/master_log_screened_in.rds imported as ml with 442 rows and 55 columns.
# 2023-08-25: data/tlfb/tlfb.rds imported as tlfb with 1768 rows and 21 columns.
# 2023-08-25: data/arrest/arrest.rds imported as arrest with 442 rows and 16 columns.
# 2023-08-25: data/bridge_session_data/bridge_wide.rds imported as bridge with 442 rows and 20 columns.
# 2023-08-25: data/ddt/ddt.rds imported as ddt with 1768 rows and 4 columns.
```


# üößData management

## Make id character

When we attempt to merge the individual data sets below, we will get a lot of errors that look like:

Error: Can't join on `x$id` x `y$id` because of incompatible types. ‚Ñπ `x$id` is of type <character>>. ‚Ñπ `y$id` is of type <double>>.

Instead of dealing with these errors one at a time, we will just coerce the `id` variable to character type here in all data frames.

In some data frames, the `id` variable is named `subject`. We will rename all instances of `subject` to `id`.

```{r}
# Keep only the R data frame names from the data_frames object. We no longer need the file paths.
data_frames <- names(data_frames)
```

```{r}
# Loop over each data frame
for (i in seq_along(data_frames)) {
  
  # Grab the data frame from the global environment
  df <- get(data_frames[[i]], envir = .GlobalEnv)
  
  # If there is a column named "subject", change the name to "id"
  if ("subject" %in% names(df)) {
    df <- rename(df, "id" = "subject")
  }
  
  # If there is a column named "GROUP", change the name to "group"
  if ("GROUP" %in% names(df)) {
    df <- rename(df, "group" = "GROUP")
  }
  
  # Coerce id to character type
  df <- mutate(df, id = as.character(id))
  
  x <- c("id", "group")
  x <- gsub("NULL", "0", x)
  suppressWarnings(x_num <- as.numeric(x))

  # Save updated data frames back to the global environment
  assign(data_frames[[i]], df, envir = .GlobalEnv)
}

# Clean up
rm(data_frames, i)
```

## Clean group value

Group assignment values from across visits can be conflicting. Additionally, group assignments between data collection instruments (i.e., QDS, REDCap, and Master Log) can be conflicting.

### QDS group values

First, gather all of the group information from the QDS data.

```{r}
group_qds <- qds %>%
  select(id, group, visit) %>% 
  arrange(id, group, visit) %>% 
  
  # Fill values of group down within id
  group_by(id) %>% 
  tidyr::fill(group, .direction = "downup") %>% 
  
  # Now check for multiple group values within id
  mutate(mult_group = unique(group) %>% length() > 1) %>% 
  ungroup()
```

Manually review id's with multiple group values

```{r}
group_qds %>% 
  filter(mult_group == TRUE)
```

**NOTE on multiple groups per id:**
Manually fix group value and let James know that they need to be fixed in QDS. After they are fixed, they will no longer show up here. Still, use these notes to keep a record.

2021-01-11, From James: 
* P2057: V3 grouping entered incorrectly on QDS. Entered 'UCM' (1) instead of 'L2C' (3) 
2023-01-31, From Sangeeta:
* P2356: V3 grouping entered incorrectly on QDS. Entered 'L2C' (3) instead of 'UCM+SP' (2) 

```{r}
# Do it this way instead of with dplyr, so you don't have to mess with class
group_qds$group[group_qds$id == 2057] <- 3
group_qds$group[group_qds$id == 2356] <- 2
```

Do one more check for multiple group values

Adding a stop function for when this file is sourced.

```{r}
# For data checks
check_qds_group_values <- group_qds %>% 
  group_by(id) %>% 
  # Now check for multiple group values within id
  filter(unique(group) %>% length() > 1)

if (nrow(check_qds_group_values) > 0) {
  stop("At least one participant in the QDS data is assigned to more than one group. Please investigate further in data_survey_21_merge.Rmd.")
}
```

Now, the value of group is the same in every row for each id. So, just use the first row for each id.

```{r}
# Manually fill in data values in the QDS data because there was no group assigned at visit 1 and we filtered for the first row only in the code chunk above.
group_qds$group[group_qds$id == 2252] <- 2
group_qds$group[group_qds$id == 2253] <- 3

qds_id_group <- group_qds %>% 
  group_by(id) %>% 
  filter(row_number() == 1) %>% 
  select(id, group) %>% 
  ungroup()
```

Manually fill in data values in the QDS data.

```{r}
group_qds$group[group_qds$id == 2252] <- 2
group_qds$group[group_qds$id == 2253] <- 3
```

### REDCap group values

Are the group values consistent in REDCap?

First, gather all of the group information from the Redcap data.

```{r}
group_rc <- rc %>%
  select(id, group) %>% 
  arrange(id, group) %>% 
  
  # Fill values of group down within id
  group_by(id) %>% 
  tidyr::fill(group, .direction = "downup") %>% 
  
  # Now check for multiple group values within id
  mutate(mult_group = unique(group) %>% length() > 1) %>% 
  ungroup()
```

Manually review id's with multiple group values

```{r}
group_rc %>% 
  filter(mult_group == TRUE)
```

**NOTE on multiple groups per id:**
Manually fix group value and let James know that they need to be fixed in REDCap. After they are fixed, they will no longer show up here. Still, use these notes to keep a record.

2023-03-20, From Sangeeta: 
* 2331: Should be in group 3 instead of group 2.
* 2398: Should be in group 3 instead of group 2.

```{r}
# Do it this way instead of with dplyr, so you don't have to mess with class
group_rc$group[group_rc$id == 2331] <- 3
group_rc$group[group_rc$id == 2398] <- 3
```

Do one more check for multiple group values

Adding a stop function for when this file is sourced.

```{r}
# For data checks
check_redcap_group_values <- group_rc %>%
  group_by(id) %>%
  filter(unique(id, group) %>% length() > 1)

if (nrow(check_redcap_group_values) > 0) (
  stop("At least one participant in the REDCap data is assigned to more than one group. Please investigate further in data_survey_21_merge.Rmd.")
)
```

So now we don't need to worry about visit number. We can just keep one row per id, and check to make sure that group in REDCap matches group in the QDS data.

```{r}
rc_id_group <- group_rc %>% 
  group_by(id) %>% 
  select(id, group) %>% 
  distinct(id, group) %>% 
  ungroup()
```

Adding a stop function for when this file is sourced.

Manually check for differences in QDS and Redcap.

```{r}
# Join REDCap id and group with QDS id and group by id

# For data checks
left_join(
  rc_id_group, qds_id_group,
  by = "id", "group",
  suffix = c("_rc","_qds")
) %>%
  
  # Check for differences in group for each id
  rowwise() %>%
  # mutate(diff = group_rc - group_qds) %>% 
  mutate(diff = length(unique(c_across(group_rc:group_qds))) > 1) %>% 
  filter(diff)
```

2023-03-20: When participants complete visit 3 via REDCap, they don't get a group value in QDS. Therefore, there are multiple missing group values in QDS for group.

### Master log group values

Supplement with Excel master log data.

First, gather all of the group information from the Master log data.

```{r}
group_ml <- ml %>%
  select(id, group) %>% 
  arrange(id, group) %>% 
  
  # Fill values of group down within id
  group_by(id) %>% 
  tidyr::fill(group, .direction = "downup") %>% 
  
  # Now check for multiple group values within id
  mutate(mult_group = unique(group) %>% length() > 1) %>% 
  ungroup()
```

Manually review id's with multiple group values

```{r}
group_ml %>% 
  filter(mult_group == TRUE)
```

Manually check for differences between group assignment in QDS and master log.

```{r}
check_qds_ml_group_diffs <- left_join(
  select(group_ml, -mult_group),
  qds_id_group, 
  by = "id",
  suffix = c("_ml", "_qds")
) %>%
  rowwise() %>% 
  mutate(diff = length(unique(c_across(c(group_ml, group_qds)))) > 1) %>% 
  filter(diff) %>% 
  print()
```

There are a bunch of id's with group membership data in master log, but not in QDS. Mostly, because these people haven't completed a v3 in QDS yet. We will go ahead and fill in the missing group data from the master log.

Below, we will formally check to see if there are any conflicting group values aside from group simply being missing in the QDS data. We will also wrap this data check in a stop function for when this file is sourced.

```{r}
# For data checks
check_qds_ml_group_diffs_not_na <- check_qds_ml_group_diffs %>% 
  filter(!is.na(group_qds) & diff == TRUE)

if (nrow(check_qds_ml_group_diffs_not_na) > 0) {
  stop("At least one participant is assigned to different groups in the QDS and master log data. This not simply due to a missing group value in master log. Please investigate further in data_survey_21_merge.Rmd.")
}
```

Now there are no "conflicts" between group in the QDS data and group in the master log. The differences were all simply due to the fact that there is no group membership information at all in QDS for these participants. Therefore, we can just go ahead and row bind. In the future, if there are conflicts between group_diffs\$group_diffs and group_diffs\$group_qds, we will need to manage them.

```{r}
group_membership_key <- qds_id_group %>%
  full_join(
    check_qds_ml_group_diffs %>% 
      select(id, group_ml), 
    by = "id",
  ) %>% 
  
  # Change class of group_ml to prevent error:
  # `false` must have class `numeric`, not class `haven_labelled/vctrs_vctr/double`
  mutate(group_ml = haven::labelled(group_ml)) %>% 
  mutate(group = if_else(is.na(group), group_ml, group)) %>% 
  select(-group_ml)
```

Make sure there are no duplicated ids in `group_membership_key` 

```{r}
if (length(unique(group_membership_key$id)) != nrow(group_membership_key)) {
  stop(
    "There are duplicate ids in `group_membership_key`. Investigate in data_survey_21_merge.Rmd"
  )
}
```

```{r}
# Clean up the data checking objects
rm(
  check_qds_group_values, check_qds_ml_group_diffs, check_qds_ml_group_diffs_not_na,
  check_redcap_group_values, group_rc, group_qds, group_membership_key
)
```

At this point, `group_membership_key` contains the final group value we will use for each participant. After merging all the other data sets below, we will add the corrected group membership information. 

# üîÑ Merge data 

## QDS and REDCap

### Checking column names

We want to row bind the QDS and REDCap data frames. To do that correctly, the column names in REDCap need to match the column names in QDS identically. Below, we will check for differences in column names.

```{r}
qds_names <- names(qds)
rc_names <- names(rc)
```

Run check when sourcing this file. Make sure there aren't any column names in REDCap that don't exist in QDS.

```{r}
if (length(setdiff(rc_names, qds_names)) > 0) {
  stop(
    "There is at least one column name in REDCap that doesn't exist in QDS. There should not be any. Investigate in data_survey_21_merge.Rmd"
  )
}
```

```{r}
rm(qds_names, rc_names)
```

### Bind QDS and REDCap

```{r}
qds <- qds %>%
  mutate(
    vac_3 = as.character(vac_3)
  )
rc <- rc %>%
  mutate(
    vac_3 = as.character(vac_3)
  )
l2c_survey <- qds %>%
  bind_rows(rc) %>% 
  arrange(id, visit)
```

```{r}
dim(l2c_survey) # 1614 1049
```

## Master log

Some of the information in master log is redundant, so we will subset selected columns that are not redundant before merging.

We will also add "ml" to the beginning of every column name in the master log. This is to prevent duplicate names (e.g. `gender.x` and `gender.y` when we join below)

```{r}
ml_sub <- ml %>% 
  select(id, status, group, name_first:v5_r_completed) %>% 
  rename_with(~ paste0("ml_", .x))
```

Run check when sourcing this file. Make sure there is one row per id in master log before joining.

```{r}
if (nrow(ml_sub) != length(unique(ml_sub$ml_id))) {
  stop(
    "Master log has more than one row per id. Investigate in data_survey_21_merge.Rmd"
  )
}

```

There are also more people in the Master log than there are in the QDS/REDCap data. This is because the Master Log is updated more frequently than the QDS/REDCap data.

Put in a check for this. If it fails, you probably need to update the Master Log import.

```{r}
if (length(unique(l2c_survey$id)) > length(unique(ml_sub$ml_id))) {
  stop(
    "There are more people in the Master log than there are in the QDS/REDCap data. If it fails, you probably need to update the Master Log import. Investigate in data_survey_21_merge.Rmd"
  )
}

```

### Join combined QDS/REDCap columns to ML

Join combined QDS/REDCap columns to ML instead of joining ML to combined QDS/REDCap columns becasue ML is more complete (i.e., has data for a greater number of participants).

```{r}
l2c_survey <- ml_sub %>%
  left_join(l2c_survey, by = c("ml_id" = "id")) %>% 
  rename(id = ml_id)
```

```{r}
dim(l2c_survey) # 1614 1076
```

## TLFB

Join TLFB to l2c_survey instead of joining l2c_survey to TLFB because TLFB does not contain a row for visit 2.

```{r}
l2c_survey <- l2c_survey %>%
  left_join(tlfb, by = c("id", "visit"))
```

```{r}
dim(l2c_survey) # 1614 1095
```

## Arrest data 

It looks like there is only one row per id. Check to make sure this is always the case. The join below will expect this condition. 

```{r}
arrest %>%
  group_by(id) %>% 
  filter(max(row_number()) > 1)
```

```{r}
arrest_one_row_per_id <- arrest %>% 
  summarise(one_row_per_id = nrow(.) == length(unique(id))) %>% 
  pull() 

if (!arrest_one_row_per_id) {
  stop(
    "The arrest data has more than one row per id. Investigate in data_survey_21_merge.d"
  )
}

rm(arrest_one_row_per_id)
```

```{r}
l2c_survey <- l2c_survey %>%
  left_join(arrest, by = "id")
```

```{r}
dim(l2c_survey) # 1614 1110
```

## Bridge sessions data

It looks like there is only one row per id. Check to make sure this is always the case. The join below will expect this condition. 

```{r}
bridge_one_row_per_id <- bridge %>% 
  summarise(one_row_per_id = nrow(.) == length(unique(id))) %>% 
  pull() 

if (!bridge_one_row_per_id) {
  stop(
    "The Bridge session data has more than one row per id. Investigate in data_survey_21_merge.Rmd"
  )
}

rm(bridge_one_row_per_id)
```

```{r}
l2c_survey <- l2c_survey %>%
  left_join(bridge, by = "id")
```

```{r}
dim(l2c_survey) # 1614 1129
```

## DDT data

```{r}
l2c_survey <- l2c_survey %>%
  left_join(ddt, by = c("id", "visit"))
```

```{r}
dim(l2c_survey) # 1614 1131
```


# Set group status

Use the `ml_group` to set the final group status for each participant.

```{r}
l2c_survey <- l2c_survey %>%
  select(-group) %>% 
  select(id, visit, date_visit, group = ml_group, everything())
```

Create a factor version of the group variable

# üî¥ Fix

2023-08-25: Sangeeta reorders all of the columns below in the section titled, "Reorder columns to follow logical order based on visit/chronology". However, should does it by column number rather than column name. So, if I insert the new factor version of the column here, it messes up her code. I don't have time to fix it right now, but I need to come back and fix it later.

```{r}
# l2c_survey <- l2c_survey |>
#   fact_reloc(group, 1:3, c("UCM", "UCM+SP", "L2C"))
```

```{r}
dim(l2c_survey) # 1614 1129
```

Make sure we get a warning if the number of columns in `l2c_survey` changes.

```{r}
if (ncol(l2c_survey) != 1129) {
  stop(
    "The number of columns in l2c_survey is different than expected.",
    " The expected number was 1,132.",
    " The actual number was ", ncol(l2c_survey), ".",
    " Investigate in data_survey_21_merge.Rmd"
  )
}

# 2023-03-20 Error: The number of columns in l2c_survey is different than expected. The expected number was 1,200. The actual number was 1184. Investigate in data_survey_21_merge.Rmd

# 2023-03-20 Column Number Discrepancies
  # 13 columns in REDCap are not used anymore for data collection, so reason why there's a 21 column difference includes these 13.
# There are 4 accounted variables for phone interviews not included.
# There are 4 unaccounted variables that have not been identified.
# 2023-04-19 There are also "complete" timestamp variables that do not need to be included in the merged dataset.

# 2023-04-19 Error: The number of columns in l2c_survey is different than expected. The expected number was 1,200. The actual number was 1131. Investigate in data_survey_21_merge.Rmd
  # New variable names and uncalculated variables were accounted for in merge of datasets, and need to be audited against "22_calculated_columns.Rmd."

# 2023-04-20 Error: The number of columns in l2c_survey is different than expected. The expected number was 1,200. The actual number was 1221. Investigate in data_survey_21_merge.Rmd

# 2023-05-02 Error: The number of columns in l2c_survey is different than expected. The expected number was 1,200. The actual number was 1132. Investigate in data_survey_21_merge.Rmd
```


# Reorder columns to follow logical order based on visit/chronology

```{r}
# DDT
l2c_survey <- l2c_survey %>%
  mutate(
    ddt_k = as.character(ddt_k)
    ) %>%
  mutate(
    ddt_ed50 = as.character(ddt_ed50)
    ) %>%
  relocate(1125:1126, .after = c(148))

# TLFB
l2c_survey <- l2c_survey %>%
  mutate(
    days_followed = as.character(days_followed)
    ) %>%
  mutate(
    num_days_homeless = as.character(num_days_homeless)
    ) %>%
  mutate(
    per_days_homeless = as.character(per_days_homeless)
    ) %>%
  mutate(
    num_days_home = as.character(num_days_home)
    ) %>%
  mutate(
    est_days_homeless_yr = as.character(est_days_homeless_yr)
    ) %>%
  mutate(
    avg_days_homeless_wk = as.character(avg_days_homeless_wk)
    ) %>%
  mutate(
    flag_out_of_window = as.character(flag_out_of_window)
    ) %>%
  relocate(1074:1092, .before = 151)

# Arrest
l2c_survey <- l2c_survey %>%
  relocate(1093:1107, .before = c(231))

## Calculated Variables
# MMS
l2c_survey <- l2c_survey %>%
  relocate(794:796, .after = c(129))

# PHQ
l2c_survey <- l2c_survey %>%
  relocate(797:808, .after = c(349))

# HSI
l2c_survey <- l2c_survey %>%
  relocate(809:810, .after = c(673))

# AQ
l2c_survey <- l2c_survey %>%
  relocate(813:817, .after = c(735))

# CES-D
l2c_survey <- l2c_survey %>%
  relocate(818:833, .after = c(750)) 

# ISE
l2c_survey <- l2c_survey %>%
  relocate(834:842, .after = c(778)) 

# FSS
l2c_survey <- l2c_survey %>%
  relocate(1103:1104, .after = c(1028))

# Friends/Family Smoke (HSI)
l2c_survey <- l2c_survey %>%
  relocate(861:862, .after = c(675))

# TCU/CJ CEST
l2c_survey <- l2c_survey %>%
  relocate(1034:1036, .after = c(947))

# Friends/Family Smoke (HSI)
l2c_survey <- l2c_survey %>%
  relocate(861:862, .after = c(675))

# PTSD
l2c_survey <- l2c_survey %>%
  relocate(849:850, .after = c(567))

# MMD
l2c_survey <- l2c_survey %>%
  relocate(1047, .after = c(967))

# TCU/CJ CEST
l2c_survey <- l2c_survey %>%
  relocate(1105:1107, .after = c(1047))

# TCU/CJ CEST
l2c_survey <- l2c_survey %>%
  relocate(1042:1043, .after = c(1050))

# TCU/CJ CEST
l2c_survey <- l2c_survey %>%
  relocate(1049:1050, .before = c(1046))

# TCU DS
l2c_survey <- l2c_survey %>%
  relocate(1022:1025, .after = c(883))

# PBQ
l2c_survey <- l2c_survey %>%
  relocate(1026, .after = c(699))

# TCU/CJ CEST
l2c_survey <- l2c_survey %>%
  relocate(1038:1050, .after = c(955))

# TCU/CJ CEST
l2c_survey <- l2c_survey %>%
  relocate(1038:1050, .after = c(955))

# MMD
l2c_survey <- l2c_survey %>%
  relocate(972:986, .after = c(720))

# FSS
l2c_survey <- l2c_survey %>%
  relocate(1040:1050, .after = c(927))

# MS
l2c_survey <- l2c_survey %>%
  relocate(701:704, .before = c(939))

# FSS
l2c_survey <- l2c_survey %>%
  relocate(1040:1050, .after = c(927))

# SB
l2c_survey <- l2c_survey %>%
  relocate(1040:1050, .after = c(927))

# ULS, PV, PS, DTS
l2c_survey <- l2c_survey %>%
  relocate(998:1041, .before = c(742))

# BRFSS Sleep
l2c_survey <- l2c_survey %>%
  relocate(903:904, .after = c(677))

# BRFSS Sleep
l2c_survey <- l2c_survey %>%
  relocate(1106:1107, .after = c(679))

# ULS
l2c_survey <- l2c_survey %>%
  relocate(1053, .after = c(766))

# PS
l2c_survey <- l2c_survey %>%
  relocate(1054:1056, .after = c(744))

# PS
l2c_survey <- l2c_survey %>%
  relocate(745:747, .after = c(777))

# DTS
l2c_survey <- l2c_survey %>%
  relocate(1057:1076, .after = c(793))

# DS
l2c_survey <- l2c_survey %>%
  relocate(953:980, .before = c(570))

# ULS 
l2c_survey <- l2c_survey %>%
  relocate(1068:1076, .after = c(997))

# Health Insurance Q
l2c_survey <- l2c_survey %>%
  relocate(977, .before = c(195))

# PBQ, FSS, PV, PS, DTS
l2c_survey <- l2c_survey %>%
  relocate(981:1028, .after = c(733))

# DTS Total
l2c_survey <- l2c_survey %>%
  relocate(733, .after = c(740))

# DTS
l2c_survey <- l2c_survey %>%
  relocate(747:750, .after = c(781))

# SB
l2c_survey <- l2c_survey %>%
  relocate(782:797, .after = c(807))

# ULS, PV, PS, DTS
l2c_survey <- l2c_survey %>%
  relocate(747:781, .after = c(822))

# TCU CJ CEST
l2c_survey <- l2c_survey %>%
  relocate(823:828, .after = c(750))

# DS
l2c_survey <- l2c_survey %>%
  relocate(571:587, .before = c(565))

# BRFSS Sleep
l2c_survey <- l2c_survey %>%
  relocate(715:719, .before = c(707))

# HSI
l2c_survey <- l2c_survey %>%
  relocate(718:719, .after = c(706))

# FSS
l2c_survey <- l2c_survey %>%
  relocate(831:841, .after = c(746))

# TCU CJ CEST
l2c_survey <- l2c_survey %>%
  relocate(842:843, .before = c(758))

# TCU CJ CEST
l2c_survey <- l2c_survey %>%
  relocate(845, .after = c(759))

# ULS
l2c_survey <- l2c_survey %>%
  relocate(845, .before = c(820))

# PS
l2c_survey <- l2c_survey %>%
  relocate(852:853, .after = c(827))

# PS
l2c_survey <- l2c_survey %>%
  relocate(854, .after = c(829))

# MMD
l2c_survey <- l2c_survey %>%
  relocate(849:860, .after = c(797))

# VAC
l2c_survey <- l2c_survey %>%
  relocate(859:860, .after = c(795))

# MMD
l2c_survey <- l2c_survey %>%
  relocate(861, .after = c(811))

# ULS
l2c_survey <- l2c_survey %>%
  relocate(862:870, .before = c(823))

# LSN
l2c_survey <- l2c_survey %>%
  relocate(1008:1009, .after = c(962))

# PTSD
l2c_survey <- l2c_survey %>%
  relocate(1010:1011, .after = c(585))

# LSN
l2c_survey <- l2c_survey %>%
  relocate(588, .after = c(966))

# DD
l2c_survey <- l2c_survey %>%
  relocate(588, .after = c(823))

# T
l2c_survey <- l2c_survey %>%
  relocate(1027:1028, .after = c(702))

# SRH
l2c_survey <- l2c_survey %>%
  relocate(1014, .after = c(564))

# TCU CJ CEST 
l2c_survey <- l2c_survey %>%
  relocate(1040:1076, .after = c(760))

# ALCF
l2c_survey <- l2c_survey %>%
  relocate(1052:1054, .after = c(735))

# ANTHRO
l2c_survey <- l2c_survey %>%
  relocate(1055:1060, .after = c(147))

# SRH 
l2c_survey <- l2c_survey %>%
  relocate(1061:1064, .after = c(571))

# VAC
l2c_survey <- l2c_survey %>%
  relocate(1069:1072, .after = c(847))

# VAC
l2c_survey <- l2c_survey %>%
  relocate(851, .after = c(852))

# MS
l2c_survey <- l2c_survey %>%
  relocate(1073:1076, .after = c(773))

# ALC/DRUG- TLFB
l2c_survey <- l2c_survey %>%
  relocate(161:172, .after = c(748))

# LOC- TLFB
l2c_survey <- l2c_survey %>%
  relocate(160:166, .after = c(1027))
```

# De-identify columns with PT names, specific info to PT (PHI)

```{r}
l2c_survey <- l2c_survey %>%
  mutate(
    ml_name_first = as.character(ml_name_first)
  ) %>%
  mutate(
    ml_name_middle_init = as.character(ml_name_middle_init)
  ) %>%
  mutate(
    ml_name_last = as.character(ml_name_last)
  ) %>%
  select(1:5, 9:11, 13, 15, 18:1129)
```

# üñ®Print a message for when this file is being sourced

```{r}
cat(
  paste0(Sys.Date(), ":"),
  "Combined Participant data cleaned with", nrow(l2c_survey), 
  "rows and", ncol(l2c_survey), "columns.\n"
)
# 2022-07-11: Combined Participant data cleaned with 1157 rows and 1202 columns.
# 2023-03-20: Combined Participant data cleaned with 1601 rows and 1184 columns.
# 2023-04-18: Combined Participant data cleaned with 1601 rows and 1184 columns.
# 2023-04-19: Combined Participant data cleaned with 1770 rows and 1131 columns.
# 2023-04-20: Combined Participant data cleaned with 1769 rows and 1221 columns.
# 2023-05-02: Combined Participant data cleaned with 48064 rows and 1132 columns.
# 2023-05-11: Combined Participant data cleaned with 1611 rows and 1129 columns.
# 2023-05-15: Combined Participant data cleaned with 1614 rows and 1129 columns.
# 2023-05-16: Combined Participant data cleaned with 1614 rows and 1126 columns.
# 2023-05-20: Combined Participant data cleaned with 1614 rows and 1129 columns.
# 2023-05-20: Combined Participant data cleaned with 1614 rows and 1126 columns.
# 2023-05-31: Combined Participant data cleaned with 1614 rows and 1122 columns.
```


# üíæSave the data frame

```{r}
path <- "data/combined_participant_data/combined_participant_data.sav"
```

```{r}
write_sav(l2c_survey, path)
```

Print a message for when this file is being sourced

```{r}
cat(
  paste0(Sys.Date(), ":"),
  "Combined Participant data saved to", path, "\n"
)
```

```{r}
path <- "data/combined_participant_data/combined_participant_data.rds"
```

```{r}
write_rds(l2c_survey, path)
```

Print a message for when this file is being sourced

```{r}
cat(
  paste0(Sys.Date(), ":"),
  "Combined Participant data saved to", path, "\n"
)
```


# üóëClean up

Don't use `rm(list = ls())` because is causes R to drop the helper functions in data_survey_21_update_all_data.Rmd

```{r}
rm(list = ls()[ls() != "source_rmd"])
```
